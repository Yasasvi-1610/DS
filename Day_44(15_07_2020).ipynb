{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Day 44(15-07-2020)",
      "provenance": [],
      "collapsed_sections": [
        "sOcbTFEiPBKA",
        "pOfuwfPrPSMz",
        "A_tyvKnBP6qD",
        "t9C3L_r4Pi6m",
        "xMckMSJqFMyc",
        "8vAGvftxHu8K",
        "IuJcAPZFIfu7",
        "RPN8liiQc7Ue"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubUsE7qtMWfj",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "### **Inroduction**:\n",
        "\n",
        "\n",
        "Aiming to minimize police response time by detecting weapons in a live cctv camera. The main motivation of this project is due to the increasing number of school mass shootings in the U.S.\n",
        "\n",
        "\n",
        "### This notebook is a part of this [medium post](https://medium.com/@alaasinjab/detailed-tutorial-build-your-custom-real-time-object-detector-5ade1017fd2d)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFkCTt1hJX3a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8d3c9bd2-7b71-46c7-d386-6c7a5a0ec095"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi0JMo0RNT2Y",
        "colab_type": "text"
      },
      "source": [
        "### This notebook was designed to be ran from top to bottom without the need to mount Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65t7YUhnzDCE",
        "colab_type": "text"
      },
      "source": [
        "## Weapon Detection Using Tensorflow Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWrRz3kXDksW",
        "colab_type": "text"
      },
      "source": [
        "Workspace structure\n",
        "\n",
        "```\n",
        "gun_detection/\n",
        "        ├─ data/\n",
        "        │    ├── images/\n",
        "        │    │      ├── armas (1).jpg\n",
        "        │    │      ├── armas (2).jpg\n",
        "        │    │      └── ...\n",
        "        │    ├── train_labels/\n",
        "        │    │      ├── armas (1).xml\n",
        "        │    │      ├── armas (2).xml\n",
        "        │    │      └── ...\n",
        "        │    ├── test_labels/\n",
        "        │    │      ├── armas (10).xml\n",
        "        │    │      ├── armas (20).xml\n",
        "        │    │      └── ...\n",
        "        │    ├── label_map.pbtxt\n",
        "        │    ├── test_labels.csv\n",
        "        │    ├── train_labels.csv\n",
        "        │    ├── test_labels.record\n",
        "        │    └── train_labels.record\n",
        "        └─ models/\n",
        "             ├─ research/\n",
        "             │      ├── fine_tuned_model/\n",
        "             │      │         ├── frozen_inference_graph.pb\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── pretrained_model/\n",
        "             │      │         ├── frozen_inference_graph.pb\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── object_detection/\n",
        "             │      │         ├── utils/\n",
        "             │      │         ├── samples/\n",
        "             │      │         │      ├── samples/ \n",
        "             │      │         │      │       ├── configs/             \n",
        "             │      │         │      │       │     ├── ssd_mobilenet_v2_coco.config\n",
        "             │      │         │      │       │     ├── rfcn_resnet101_pets.config\n",
        "             │      │         │      │       │     └── ...\n",
        "             │      │         │      │       └── ... \n",
        "             │      │         │      └── ...                                \n",
        "             │      │         ├── export_inference_graph.py\n",
        "             │      │         ├── model_main.py\n",
        "             │      │         └── ...\n",
        "             │      │         \n",
        "             │      ├── training/\n",
        "             │      │         ├── events.out.tfevents.xxxxx\n",
        "             │      │         └── ...               \n",
        "             │      └── ...\n",
        "             └── ...\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMlXJ2yIV8e7",
        "colab_type": "text"
      },
      "source": [
        "## Choosing a pre training model\n",
        "The model used for this project is `ssd_mobilenet_v2_coco`.\n",
        "Check other models from [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md#coco-trained-models).\n",
        "\n",
        "Because the interestes of this project is to interfere on real time video, i am chosing a model that has a high inference speed `(ms)` with relativly high `mAP` on COCO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3_Ns54i3HgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Some models to train on\n",
        "MODELS_CONFIG = {\n",
        "    'ssd_mobilenet_v2': {\n",
        "        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n",
        "        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n",
        "    },\n",
        "    'faster_rcnn_inception_v2': {\n",
        "        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n",
        "        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n",
        "    },\n",
        "    'rfcn_resnet101': {\n",
        "        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n",
        "        'pipeline_file': 'rfcn_resnet101_pets.config',\n",
        "    }\n",
        "}\n",
        "\n",
        "# Select a model in `MODELS_CONFIG`.\n",
        "# I chose ssd_mobilenet_v2 for this project, you could choose any\n",
        "selected_model = 'ssd_mobilenet_v2'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sv3Zm042QGJy",
        "colab_type": "text"
      },
      "source": [
        "## Installing Required Packages "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68StUELaQPS2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "outputId": "8181ff74-ddce-4e5a-827f-337e025295c9"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "\n",
        "!pip install -qq Cython contextlib2 pillow lxml matplotlib\n",
        "\n",
        "!pip install -qq pycocotools"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... \r(Reading database ... 5%\r(Reading database ... 10%\r(Reading database ... 15%\r(Reading database ... 20%\r(Reading database ... 25%\r(Reading database ... 30%\r(Reading database ... 35%\r(Reading database ... 40%\r(Reading database ... 45%\r(Reading database ... 50%\r(Reading database ... 55%\r(Reading database ... 60%\r(Reading database ... 65%\r(Reading database ... 70%\r(Reading database ... 75%\r(Reading database ... 80%\r(Reading database ... 85%\r(Reading database ... 90%\r(Reading database ... 95%\r(Reading database ... 100%\r(Reading database ... 144465 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1ubuntu0.2_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1ubuntu0.2) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERyocH9U-o2Y",
        "colab_type": "text"
      },
      "source": [
        "## General imports\n",
        "Other Imports will be done after downloading some packages later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEVLeKXh-s23",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division, print_function, absolute_import\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import re\n",
        "import cv2 \n",
        "import os\n",
        "import glob\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "import io\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "from PIL import Image\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "import shutil\n",
        "import urllib.request\n",
        "import tarfile\n",
        "\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8QeHvX6gpmC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b4f35f52-d0e3-4361-bba0-c839108eba64"
      },
      "source": [
        "#we need tenorflow v 1.15.0, object detection API is removed from tf v 2.0+\n",
        "#!pip install tensorflow==1.15.0\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOcbTFEiPBKA",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Orgniazing Images and Annotations\n",
        "1. Downloading the images and annotations from the [source](https://sci2s.ugr.es/weapons-detection)  and unziping them\n",
        "2. Creating a directory `(data)` to save some data such as; images, annotation, csv, etc...\n",
        "3. Creating two directories; for the training and testing labels (not the images)\n",
        "4. Randomly splitting our labels into 80% training and 20% testing and moving the splits to their directories: `(train_labels)` & `(test_labels)` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QY-CyUQwyZr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#creates a directory for the whole project\n",
        "!mkdir gun_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHPQQmhm7RLe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f24757bb-e1e8-4577-efcc-a9debab8de31"
      },
      "source": [
        "cd gun_detection"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tp62o3a07UbP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "f0c204b8-dd14-4e4b-f289-ec22997243e1"
      },
      "source": [
        "#Training images and annotations\n",
        "\n",
        "#Source: https://sci2s.ugr.es/weapons-detection\n",
        "\n",
        "\n",
        "#download the images zip\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
        "\n",
        "#unzip the image file\n",
        "!unzip -q WeaponS.zip\n",
        "\n",
        "#download the annotations zip\n",
        "!wget https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
        "\n",
        "#unzip the annotations file\n",
        "!unzip -q WeaponS_bbox.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 02:24:26--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS.zip\n",
            "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
            "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 250005059 (238M) [application/zip]\n",
            "Saving to: ‘WeaponS.zip’\n",
            "\n",
            "WeaponS.zip         100%[===================>] 238.42M  11.2MB/s    in 21s     \n",
            "\n",
            "2020-07-15 02:24:48 (11.1 MB/s) - ‘WeaponS.zip’ saved [250005059/250005059]\n",
            "\n",
            "--2020-07-15 02:24:54--  https://sci2s.ugr.es/sites/default/files/files/TematicWebSites/WeaponsDetection/BasesDeDatos/WeaponS_bbox.zip\n",
            "Resolving sci2s.ugr.es (sci2s.ugr.es)... 150.214.190.154\n",
            "Connecting to sci2s.ugr.es (sci2s.ugr.es)|150.214.190.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1420022 (1.4M) [application/zip]\n",
            "Saving to: ‘WeaponS_bbox.zip’\n",
            "\n",
            "WeaponS_bbox.zip    100%[===================>]   1.35M  5.57MB/s    in 0.2s    \n",
            "\n",
            "2020-07-15 02:24:55 (5.57 MB/s) - ‘WeaponS_bbox.zip’ saved [1420022/1420022]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0czMMeR8GxW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating a directory to store the training and testing data\n",
        "!mkdir data\n",
        "\n",
        "# folders for the training and testing data.\n",
        "!mkdir data/images data/train_labels data/test_labels\n",
        "\n",
        "\n",
        "# combining the images and annotation in the training folder:\n",
        "# moves the images to data folder\n",
        "!mv WeaponS/* data/images\n",
        "\n",
        "# moves the annotations to data folder\n",
        "!mv WeaponS_bbox/* data/train_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y0d2xreHrH0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d02a918c-9b88-4e2c-c1eb-41579e0003bc"
      },
      "source": [
        "import os\n",
        "os.listdir('data')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test_labels', 'images', 'train_labels']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vv8pmB2D80M7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Deleting the zipped and unzipped folders \n",
        "!rm -rf WeaponS_bbox.zip  WeaponS.zip WeaponS/  WeaponS_bbox/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUl-XRwPvj4j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n",
        "# Moves the first 600 labels to the testing dir: `test_labels`\n",
        "!ls data/train_labels/* | sort -R | head -600 | xargs -I{} mv {} data/test_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmvDu-rUHz96",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b392dc5e-5f4e-4dfc-ffef-816b626be3fd"
      },
      "source": [
        "# 2400 \"images\"(xml) for training\n",
        "!ls data/train_labels/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8y-1_t7wRJc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab89349a-6d7f-4446-811d-3c6ba2a66cc5"
      },
      "source": [
        "# 600 \"images\"(xml) for testing\n",
        "!ls  data/test_labels/ | wc -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOfuwfPrPSMz",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing Images and Labels\n",
        "1. Converting the annotations from xml files to two csv files for each `train_labels/` and `train_labels/`.\n",
        "2. Creating a pbtxt file that specifies the number of class (one class in this case)\n",
        "3. Checking if the annotations for each object are placed within the range of the image width and height."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBHBFpWyEIDI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b042a86b-b97e-47f6-af1d-0ffb75a8d4f7"
      },
      "source": [
        "\n",
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "#converts the annotations/labels into one csv file for each training and testing labels\n",
        "#creats label_map.pbtxt file\n",
        "\n",
        "%cd /content/gun_detection/data\n",
        "\n",
        "\n",
        "# images extension\n",
        "images_extension = 'jpg'\n",
        "\n",
        "# takes the path of a directory that contains xml files and converts\n",
        "#  them to one csv file.\n",
        "\n",
        "# returns a csv file that contains: image name, width, height, class, xmin, ymin, xmax, ymax.\n",
        "# note: if the xml file contains more than one box/label, it will create more than one row for the same image. each row contains the info for an individual box. \n",
        "def xml_to_csv(path):\n",
        "  classes_names = []\n",
        "  xml_list = []\n",
        "\n",
        "  for xml_file in glob.glob(path + '/*.xml'):\n",
        "    tree = ET.parse(xml_file)\n",
        "    root = tree.getroot()\n",
        "    for member in root.findall('object'):\n",
        "      classes_names.append(member[0].text)\n",
        "      value = (root.find('filename').text + '.' + images_extension,\n",
        "               int(root.find('size')[0].text),\n",
        "               int(root.find('size')[1].text),\n",
        "               member[0].text,\n",
        "               int(member[4][0].text),\n",
        "               int(member[4][1].text),\n",
        "               int(member[4][2].text),\n",
        "               int(member[4][3].text))\n",
        "      xml_list.append(value)\n",
        "  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  xml_df = pd.DataFrame(xml_list, columns=column_name) \n",
        "  classes_names = list(set(classes_names))\n",
        "  classes_names.sort()\n",
        "  return xml_df, classes_names\n",
        "\n",
        "# for both the train_labels and test_labels csv files, it runs the xml_to_csv() above.\n",
        "for label_path in ['train_labels', 'test_labels']:\n",
        "  image_path = os.path.join(os.getcwd(), label_path)\n",
        "  xml_df, classes = xml_to_csv(label_path)\n",
        "  xml_df.to_csv(f'{label_path}.csv', index=None)\n",
        "  print(f'Successfully converted {label_path} xml to csv.')\n",
        "\n",
        "# Creating the `label_map.pbtxt` file\n",
        "label_map_path = os.path.join(\"label_map.pbtxt\")\n",
        "\n",
        "pbtxt_content = \"\"\n",
        "\n",
        "#creats a pbtxt file the has the class names.\n",
        "for i, class_name in enumerate(classes):\n",
        "    # display_name is optional.\n",
        "    pbtxt_content = (\n",
        "        pbtxt_content\n",
        "        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n    display_name: 'Gun'\\n }}\\n\\n\".format(i + 1, class_name)\n",
        "    )\n",
        "pbtxt_content = pbtxt_content.strip()\n",
        "with open(label_map_path, \"w\") as f:\n",
        "    f.write(pbtxt_content)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/data\n",
            "Successfully converted train_labels xml to csv.\n",
            "Successfully converted test_labels xml to csv.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtfjZcD-CCdM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "b950f22d-21c0-472c-cd96-e39e5534173b"
      },
      "source": [
        "#checking the pbtxt file\n",
        "!cat label_map.pbtxt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "item {\n",
            "    id: 1\n",
            "    name: 'pistol'\n",
            "    display_name: 'Gun'\n",
            " }"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP8gohagKFXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "9b2b1cd5-0a4c-4606-c729-6980a74caac1"
      },
      "source": [
        "# they are there!\n",
        "!ls -l"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 420\n",
            "drwxr-xr-x 2 root root 122880 Jul 15 02:25 images\n",
            "-rw-r--r-- 1 root root     62 Jul 15 02:26 label_map.pbtxt\n",
            "drwxr-xr-x 2 root root  24576 Jul 15 02:26 test_labels\n",
            "-rw-r--r-- 1 root root  32984 Jul 15 02:26 test_labels.csv\n",
            "drwxr-xr-x 2 root root 110592 Jul 15 02:26 train_labels\n",
            "-rw-r--r-- 1 root root 126937 Jul 15 02:26 train_labels.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4p7J6mFLLZf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fb240bf8-3703-4540-d745-c61f7551b99d"
      },
      "source": [
        "#checks if the images box position is placed within the image.\n",
        "\n",
        "#note: while this doesn't checks if the boxes/annotatoins are correctly\n",
        "# placed around the object, Tensorflow will through an error if this occured.\n",
        "%cd /content/gun_detection/data\n",
        "# path to images\n",
        "images_path = 'images'\n",
        "\n",
        "#loops over both train_labels and test_labels csv files to do the check\n",
        "# returns the image name where an error is found \n",
        "# return the incorrect attributes; xmin, ymin, xmax, ymax.\n",
        "for CSV_FILE in ['train_labels.csv', 'test_labels.csv']:\n",
        "  with open(CSV_FILE, 'r') as fid:  \n",
        "      print('[*] Checking file:', CSV_FILE) \n",
        "      file = csv.reader(fid, delimiter=',')\n",
        "      first = True \n",
        "      cnt = 0\n",
        "      error_cnt = 0\n",
        "      error = False\n",
        "      for row in file:\n",
        "          if error == True:\n",
        "              error_cnt += 1\n",
        "              error = False         \n",
        "          if first == True:\n",
        "              first = False\n",
        "              continue     \n",
        "          cnt += 1      \n",
        "          name, width, height, xmin, ymin, xmax, ymax = row[0], int(row[1]), int(row[2]), int(row[4]), int(row[5]), int(row[6]), int(row[7])     \n",
        "          path = os.path.join(images_path, name)\n",
        "          img = cv2.imread(path)         \n",
        "          if type(img) == type(None):\n",
        "              error = True\n",
        "              print('Could not read image', img)\n",
        "              continue     \n",
        "          org_height, org_width = img.shape[:2]     \n",
        "          if org_width != width:\n",
        "              error = True\n",
        "              print('Width mismatch for image: ', name, width, '!=', org_width)     \n",
        "          if org_height != height:\n",
        "              error = True\n",
        "              print('Height mismatch for image: ', name, height, '!=', org_height) \n",
        "          if xmin > org_width:\n",
        "              error = True\n",
        "              print('XMIN > org_width for file', name)  \n",
        "          if xmax > org_width:\n",
        "              error = True\n",
        "              print('XMAX > org_width for file', name)\n",
        "          if ymin > org_height:\n",
        "              error = True\n",
        "              print('YMIN > org_height for file', name)\n",
        "          if ymax > org_height:\n",
        "              error = True\n",
        "              print('YMAX > org_height for file', name)\n",
        "          if error == True:\n",
        "              print('Error for file: %s' % name)\n",
        "              print()\n",
        "      print()\n",
        "      print('Checked %d files and realized %d errors' % (cnt, error_cnt))\n",
        "      print(\"-----\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/data\n",
            "[*] Checking file: train_labels.csv\n",
            "\n",
            "Checked 2749 files and realized 0 errors\n",
            "-----\n",
            "[*] Checking file: test_labels.csv\n",
            "XMIN > org_width for file armas (2815).jpg\n",
            "XMAX > org_width for file armas (2815).jpg\n",
            "YMIN > org_height for file armas (2815).jpg\n",
            "YMAX > org_height for file armas (2815).jpg\n",
            "Error for file: armas (2815).jpg\n",
            "\n",
            "\n",
            "Checked 715 files and realized 1 errors\n",
            "-----\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vD5luKTsMx7F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#we have only one image with incorrect box position, we could just remove it \n",
        "#removing the image \n",
        "!rm images/'armas (2815).jpg'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze4z9bW3ZjhC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#removing the entry for it in the csv for that image as well\n",
        "\n",
        "#because we did a random split for the data, we dont know if it ended up being in training or testing\n",
        "# we will remove the image from both.\n",
        "\n",
        "#training\n",
        "#reading the training csv\n",
        "df = pd.read_csv('/content/gun_detection/data/train_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/gun_detection/data/train_labels.csv')\n",
        "\n",
        "\n",
        "#testing\n",
        "#reading the testing csv\n",
        "df = pd.read_csv('/content/gun_detection/data/test_labels.csv')\n",
        "# removing armas (2815).jpg\n",
        "df = df[df['filename'] != 'armas (2815).jpg']\n",
        "#reseting the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "#saving the df\n",
        "df.to_csv('/content/gun_detection/data/test_labels.csv')\n",
        "\n",
        "# Just for the memory\n",
        "df = None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_tyvKnBP6qD",
        "colab_type": "text"
      },
      "source": [
        "## Downloading and Preparing Tensorflow model\n",
        "1. Cloning [Tensorflow models](https://github.com/tensorflow/models.git) from the offical git repo. The repo contains the object detection API we are interseted in. \n",
        "2. Compiling the protos and adding folders to the os environment.\n",
        "3. Testing the model builder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIxz1GqJQA3f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c4442a45-fa41-49aa-e76f-d0d25a913a9b"
      },
      "source": [
        "# Downlaods Tenorflow\n",
        "%cd /content/gun_detection/\n",
        "!git clone --q https://github.com/tensorflow/models.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "me2932JPQQOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv models/official models/research/official"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjcAhsxRQ5N1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3b3e3509-cf56-47d3-c2ee-513061eb44e0"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "#compiling the proto buffers (not important to understand for this project but you can learn more about them here: https://developers.google.com/protocol-buffers/)\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "\n",
        "# exports the PYTHONPATH environment variable with the reasearch and slim folders' paths\n",
        "os.environ['PYTHONPATH'] += ':/content/gun_detection/models/research/:/content/gun_detection/models/research/slim/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n",
            "object_detection/protos/input_reader.proto: warning: Import object_detection/protos/image_resizer.proto but not used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bMNsrwTSJi2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "cef951ad-7da7-4b54-c0fc-dc3adc12d130"
      },
      "source": [
        "# testing the model builder\n",
        "!pip install tf_slim\n",
        "\n",
        "!python3 object_detection/builders/model_builder_test.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_slim\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/97/b0f4a64df018ca018cc035d44f2ef08f91e2e8aa67271f6f19633a015ff7/tf_slim-1.1.0-py2.py3-none-any.whl (352kB)\n",
            "\r\u001b[K     |█                               | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 20kB 4.8MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30kB 6.2MB/s eta 0:00:01\r\u001b[K     |███▊                            | 40kB 6.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 61kB 5.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 71kB 6.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 81kB 6.7MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 92kB 7.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 102kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 112kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 122kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████                    | 133kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 143kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 153kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 163kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 174kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 184kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 194kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 204kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 215kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 225kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 235kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 245kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 256kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 266kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 276kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 286kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 296kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 307kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 317kB 7.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 327kB 7.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 337kB 7.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 348kB 7.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 358kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf_slim) (0.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py>=0.2.2->tf_slim) (1.12.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9C3L_r4Pi6m",
        "colab_type": "text"
      },
      "source": [
        "## Generating Tf record\n",
        "- Generating two TFRecords files for the training and testing CSVs.\n",
        "- Tensorflow accepts the data as tfrecords which is a binary file that run fast with low memory usage. Instead of loading the full data into memory, Tenorflow breaks the data into batches using these TFRecords automatically"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK2unk-9LB_E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "5f141ce3-6c9c-4a16-88ea-af89eaa4c3e4"
      },
      "source": [
        "#adjusted from: https://github.com/datitran/raccoon_dataset\n",
        "\n",
        "# converts the csv files for training and testing data to two TFRecords files.\n",
        "# places the output in the same directory as the input\n",
        "\n",
        "\n",
        "from object_detection.utils import dataset_util\n",
        "%cd /content/gun_detection/models/\n",
        "\n",
        "DATA_BASE_PATH = '/content/gun_detection/data/'\n",
        "image_dir = DATA_BASE_PATH +'images/'\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "\t\tif row_label == 'pistol':\n",
        "\t\t\t\treturn 1\n",
        "\t\telse:\n",
        "\t\t\t\tNone\n",
        "\n",
        "\n",
        "def split(df, group):\n",
        "\t\tdata = namedtuple('data', ['filename', 'object'])\n",
        "\t\tgb = df.groupby(group)\n",
        "\t\treturn [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "\t\twith tf.io.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "\t\t\t\tencoded_jpg = fid.read()\n",
        "\t\tencoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "\t\timage = Image.open(encoded_jpg_io)\n",
        "\t\twidth, height = image.size\n",
        "\n",
        "\t\tfilename = group.filename.encode('utf8')\n",
        "\t\timage_format = b'jpg'\n",
        "\t\txmins = []\n",
        "\t\txmaxs = []\n",
        "\t\tymins = []\n",
        "\t\tymaxs = []\n",
        "\t\tclasses_text = []\n",
        "\t\tclasses = []\n",
        "\n",
        "\t\tfor index, row in group.object.iterrows():\n",
        "\t\t\t\txmins.append(row['xmin'] / width)\n",
        "\t\t\t\txmaxs.append(row['xmax'] / width)\n",
        "\t\t\t\tymins.append(row['ymin'] / height)\n",
        "\t\t\t\tymaxs.append(row['ymax'] / height)\n",
        "\t\t\t\tclasses_text.append(row['class'].encode('utf8'))\n",
        "\t\t\t\tclasses.append(class_text_to_int(row['class']))\n",
        "\n",
        "\t\ttf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "\t\t\t\t'image/height': dataset_util.int64_feature(height),\n",
        "\t\t\t\t'image/width': dataset_util.int64_feature(width),\n",
        "\t\t\t\t'image/filename': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/source_id': dataset_util.bytes_feature(filename),\n",
        "\t\t\t\t'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "\t\t\t\t'image/format': dataset_util.bytes_feature(image_format),\n",
        "\t\t\t\t'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "\t\t\t\t'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "\t\t\t\t'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "\t\t\t\t'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "\t\t\t\t'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "\t\t\t\t'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "\t\t}))\n",
        "\t\treturn tf_example\n",
        "\n",
        "for csv in ['train_labels', 'test_labels']:\n",
        "  writer = tf.io.TFRecordWriter(DATA_BASE_PATH + csv + '.record')\n",
        "  path = os.path.join(image_dir)\n",
        "  examples = pd.read_csv(DATA_BASE_PATH + csv + '.csv')\n",
        "  grouped = split(examples, 'filename')\n",
        "  for group in grouped:\n",
        "      tf_example = create_tf_example(group, path)\n",
        "      writer.write(tf_example.SerializeToString())\n",
        "    \n",
        "  writer.close()\n",
        "  output_path = os.path.join(os.getcwd(), DATA_BASE_PATH + csv + '.record')\n",
        "  print('Successfully created the TFRecords: {}'.format(DATA_BASE_PATH +csv + '.record'))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models\n",
            "Successfully created the TFRecords: /content/gun_detection/data/train_labels.record\n",
            "Successfully created the TFRecords: /content/gun_detection/data/test_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1zRJducWs-X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "d8bf0985-1618-496c-b901-f12577818e00"
      },
      "source": [
        "# TFRecords are created\n",
        "!ls -lX /content/gun_detection/data/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 252488\n",
            "drwxr-xr-x 2 root root    122880 Jul 15 02:29 images\n",
            "drwxr-xr-x 2 root root     24576 Jul 15 02:26 test_labels\n",
            "drwxr-xr-x 2 root root    110592 Jul 15 02:26 train_labels\n",
            "-rw-r--r-- 1 root root     35633 Jul 15 02:29 test_labels.csv\n",
            "-rw-r--r-- 1 root root    139573 Jul 15 02:29 train_labels.csv\n",
            "-rw-r--r-- 1 root root        62 Jul 15 02:26 label_map.pbtxt\n",
            "-rw-r--r-- 1 root root  46457372 Jul 15 02:31 test_labels.record\n",
            "-rw-r--r-- 1 root root 211636782 Jul 15 02:31 train_labels.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMckMSJqFMyc",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Base Model\n",
        "1. Based on the model selecting at the top of this notebook, downloading the model selected and extracting its content.\n",
        "2. Creating a dir to save the model while training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvN9Cw65FQzB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36c3c07e-a63b-452a-e52b-eb9aa3be3e07"
      },
      "source": [
        "%cd /content/gun_detection/models/research\n",
        "\n",
        "# Name of the object detection model to use.\n",
        "MODEL = MODELS_CONFIG[selected_model]['model_name']\n",
        "\n",
        "# Name of the pipline file in tensorflow object detection API.\n",
        "pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n",
        "\n",
        "#selecting the model\n",
        "MODEL_FILE = MODEL + '.tar.gz'\n",
        "\n",
        "#creating the downlaod link for the model selected\n",
        "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
        "\n",
        "#the distination folder where the model will be saved\n",
        "fine_tune_dir = '/content/gun_detection/models/research/pretrained_model'\n",
        "\n",
        "#checks if the model has already been downloaded\n",
        "if not (os.path.exists(MODEL_FILE)):\n",
        "    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
        "\n",
        "#unzipping the file and extracting its content\n",
        "tar = tarfile.open(MODEL_FILE)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "# creating an output file to save the model while training\n",
        "os.remove(MODEL_FILE)\n",
        "if (os.path.exists(fine_tune_dir)):\n",
        "    shutil.rmtree(fine_tune_dir)\n",
        "os.rename(MODEL, fine_tune_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbjXKVMmFk47",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "3472adc7-9b54-46fa-cd8e-4a7909f54bd3"
      },
      "source": [
        "#checking the content of the pretrained model.\n",
        "# this is the directory of the \"fine_tune_checkpoint\" that is used in the config file.\n",
        "!echo {fine_tune_dir}\n",
        "!ls -alh {fine_tune_dir}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gun_detection/models/research/pretrained_model\n",
            "total 135M\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 .\n",
            "drwxr-xr-x 64 root   root  4.0K Jul 15 02:31 ..\n",
            "-rw-r--r--  1 345018 89939   77 Mar 30  2018 checkpoint\n",
            "-rw-r--r--  1 345018 89939  67M Mar 30  2018 frozen_inference_graph.pb\n",
            "-rw-r--r--  1 345018 89939  65M Mar 30  2018 model.ckpt.data-00000-of-00001\n",
            "-rw-r--r--  1 345018 89939  15K Mar 30  2018 model.ckpt.index\n",
            "-rw-r--r--  1 345018 89939 3.4M Mar 30  2018 model.ckpt.meta\n",
            "-rw-r--r--  1 345018 89939 4.2K Mar 30  2018 pipeline.config\n",
            "drwxr-xr-x  3 345018 89939 4.0K Mar 30  2018 saved_model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnjQgJZiGAcA",
        "colab_type": "text"
      },
      "source": [
        "## Configuring the Training Pipeline\n",
        "1. Adding the path for the TFRecords files and pbtxt,batch_size,num_steps,num_classes to the configuration file.\n",
        "2. Adding some Image augmentation.\n",
        "3. Creating a directory to save the model at each checkpoint while training. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az14XVo31Ujp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6d4f112-ff05-4bce-aafe-b80c0772fa45"
      },
      "source": [
        "\n",
        "#the path to the folder containing all the sample config files\n",
        "CONFIG_BASE = \"/content/gun_detection/models/research/object_detection/samples/configs/\"\n",
        "\n",
        "#path to the specified model's config file\n",
        "model_pipline = os.path.join(CONFIG_BASE, pipeline_file)\n",
        "model_pipline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT3m6pbXpN_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e3b70c15-26f7-48fc-d2dc-c4b90c9d6694"
      },
      "source": [
        "#check the sample config file that is provided by the tf model\n",
        "!cat /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# SSD with Mobilenet v2 configuration for MSCOCO Dataset.\n",
            "# Users should configure the fine_tune_checkpoint field in the train config as\n",
            "# well as the label_map_path and input_path fields in the train_input_reader and\n",
            "# eval_input_reader. Search for \"PATH_TO_BE_CONFIGURED\" to find the fields that\n",
            "# should be configured.\n",
            "\n",
            "model {\n",
            "  ssd {\n",
            "    num_classes: 90\n",
            "    box_coder {\n",
            "      faster_rcnn_box_coder {\n",
            "        y_scale: 10.0\n",
            "        x_scale: 10.0\n",
            "        height_scale: 5.0\n",
            "        width_scale: 5.0\n",
            "      }\n",
            "    }\n",
            "    matcher {\n",
            "      argmax_matcher {\n",
            "        matched_threshold: 0.5\n",
            "        unmatched_threshold: 0.5\n",
            "        ignore_thresholds: false\n",
            "        negatives_lower_than_unmatched: true\n",
            "        force_match_for_each_row: true\n",
            "      }\n",
            "    }\n",
            "    similarity_calculator {\n",
            "      iou_similarity {\n",
            "      }\n",
            "    }\n",
            "    anchor_generator {\n",
            "      ssd_anchor_generator {\n",
            "        num_layers: 6\n",
            "        min_scale: 0.2\n",
            "        max_scale: 0.95\n",
            "        aspect_ratios: 1.0\n",
            "        aspect_ratios: 2.0\n",
            "        aspect_ratios: 0.5\n",
            "        aspect_ratios: 3.0\n",
            "        aspect_ratios: 0.3333\n",
            "      }\n",
            "    }\n",
            "    image_resizer {\n",
            "      fixed_shape_resizer {\n",
            "        height: 300\n",
            "        width: 300\n",
            "      }\n",
            "    }\n",
            "    box_predictor {\n",
            "      convolutional_box_predictor {\n",
            "        min_depth: 0\n",
            "        max_depth: 0\n",
            "        num_layers_before_predictor: 0\n",
            "        use_dropout: false\n",
            "        dropout_keep_probability: 0.8\n",
            "        kernel_size: 1\n",
            "        box_code_size: 4\n",
            "        apply_sigmoid_to_scores: false\n",
            "        conv_hyperparams {\n",
            "          activation: RELU_6,\n",
            "          regularizer {\n",
            "            l2_regularizer {\n",
            "              weight: 0.00004\n",
            "            }\n",
            "          }\n",
            "          initializer {\n",
            "            truncated_normal_initializer {\n",
            "              stddev: 0.03\n",
            "              mean: 0.0\n",
            "            }\n",
            "          }\n",
            "          batch_norm {\n",
            "            train: true,\n",
            "            scale: true,\n",
            "            center: true,\n",
            "            decay: 0.9997,\n",
            "            epsilon: 0.001,\n",
            "          }\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    feature_extractor {\n",
            "      type: 'ssd_mobilenet_v2'\n",
            "      min_depth: 16\n",
            "      depth_multiplier: 1.0\n",
            "      conv_hyperparams {\n",
            "        activation: RELU_6,\n",
            "        regularizer {\n",
            "          l2_regularizer {\n",
            "            weight: 0.00004\n",
            "          }\n",
            "        }\n",
            "        initializer {\n",
            "          truncated_normal_initializer {\n",
            "            stddev: 0.03\n",
            "            mean: 0.0\n",
            "          }\n",
            "        }\n",
            "        batch_norm {\n",
            "          train: true,\n",
            "          scale: true,\n",
            "          center: true,\n",
            "          decay: 0.9997,\n",
            "          epsilon: 0.001,\n",
            "        }\n",
            "      }\n",
            "    }\n",
            "    loss {\n",
            "      classification_loss {\n",
            "        weighted_sigmoid {\n",
            "        }\n",
            "      }\n",
            "      localization_loss {\n",
            "        weighted_smooth_l1 {\n",
            "        }\n",
            "      }\n",
            "      hard_example_miner {\n",
            "        num_hard_examples: 3000\n",
            "        iou_threshold: 0.99\n",
            "        loss_type: CLASSIFICATION\n",
            "        max_negatives_per_positive: 3\n",
            "        min_negatives_per_image: 3\n",
            "      }\n",
            "      classification_weight: 1.0\n",
            "      localization_weight: 1.0\n",
            "    }\n",
            "    normalize_loss_by_num_matches: true\n",
            "    post_processing {\n",
            "      batch_non_max_suppression {\n",
            "        score_threshold: 1e-8\n",
            "        iou_threshold: 0.6\n",
            "        max_detections_per_class: 100\n",
            "        max_total_detections: 100\n",
            "      }\n",
            "      score_converter: SIGMOID\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_config: {\n",
            "  batch_size: 24\n",
            "  optimizer {\n",
            "    rms_prop_optimizer: {\n",
            "      learning_rate: {\n",
            "        exponential_decay_learning_rate {\n",
            "          initial_learning_rate: 0.004\n",
            "          decay_steps: 800720\n",
            "          decay_factor: 0.95\n",
            "        }\n",
            "      }\n",
            "      momentum_optimizer_value: 0.9\n",
            "      decay: 0.9\n",
            "      epsilon: 1.0\n",
            "    }\n",
            "  }\n",
            "  fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED/model.ckpt\"\n",
            "  fine_tune_checkpoint_type:  \"detection\"\n",
            "  # Note: The below line limits the training process to 200K steps, which we\n",
            "  # empirically found to be sufficient enough to train the pets dataset. This\n",
            "  # effectively bypasses the learning rate schedule (the learning rate will\n",
            "  # never decay). Remove the below line to train indefinitely.\n",
            "  num_steps: 200000\n",
            "  data_augmentation_options {\n",
            "    random_horizontal_flip {\n",
            "    }\n",
            "  }\n",
            "  data_augmentation_options {\n",
            "    ssd_random_crop {\n",
            "    }\n",
            "  }\n",
            "}\n",
            "\n",
            "train_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_train.record-?????-of-00100\"\n",
            "  }\n",
            "  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
            "}\n",
            "\n",
            "eval_config: {\n",
            "  num_examples: 8000\n",
            "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
            "  # Remove the below line to evaluate indefinitely.\n",
            "  max_evals: 10\n",
            "}\n",
            "\n",
            "eval_input_reader: {\n",
            "  tf_record_input_reader {\n",
            "    input_path: \"PATH_TO_BE_CONFIGURED/mscoco_val.record-?????-of-00010\"\n",
            "  }\n",
            "  label_map_path: \"PATH_TO_BE_CONFIGURED/mscoco_label_map.pbtxt\"\n",
            "  shuffle: false\n",
            "  num_readers: 1\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfsl5CsDGY3-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "17c3dcec-9616-4614-dded-4ab7c8a6ee41"
      },
      "source": [
        "#editing the configuration file to add the path for the TFRecords files, pbtxt,batch_size,num_steps,num_classes.\n",
        "# any image augmentation, hyperparemeter tunning (drop out, batch normalization... etc) would be editted here\n",
        "\n",
        "%%writefile {model_pipline}\n",
        "model {\n",
        "  ssd {\n",
        "    num_classes: 1 # number of classes to be detected\n",
        "    box_coder {\n",
        "      faster_rcnn_box_coder {\n",
        "        y_scale: 10.0\n",
        "        x_scale: 10.0\n",
        "        height_scale: 5.0\n",
        "        width_scale: 5.0\n",
        "      }\n",
        "    }\n",
        "    matcher {\n",
        "      argmax_matcher {\n",
        "        matched_threshold: 0.5\n",
        "        unmatched_threshold: 0.5\n",
        "        ignore_thresholds: false\n",
        "        negatives_lower_than_unmatched: true\n",
        "        force_match_for_each_row: true\n",
        "      }\n",
        "    }\n",
        "    similarity_calculator {\n",
        "      iou_similarity {\n",
        "      }\n",
        "    }\n",
        "    anchor_generator {\n",
        "      ssd_anchor_generator {\n",
        "        num_layers: 6\n",
        "        min_scale: 0.2\n",
        "        max_scale: 0.95\n",
        "        aspect_ratios: 1.0\n",
        "        aspect_ratios: 2.0\n",
        "        aspect_ratios: 0.5\n",
        "        aspect_ratios: 3.0\n",
        "        aspect_ratios: 0.3333\n",
        "      }\n",
        "    }\n",
        "    # all images will be resized to the below W x H.\n",
        "    image_resizer { \n",
        "      fixed_shape_resizer {\n",
        "        height: 300\n",
        "        width: 300\n",
        "      }\n",
        "    }\n",
        "    box_predictor {\n",
        "      convolutional_box_predictor {\n",
        "        min_depth: 0\n",
        "        max_depth: 0\n",
        "        num_layers_before_predictor: 0\n",
        "        #use_dropout: false\n",
        "        use_dropout: true # to counter over fitting. you can also try tweaking its probability below\n",
        "        dropout_keep_probability: 0.8\n",
        "        kernel_size: 1\n",
        "        box_code_size: 4\n",
        "        apply_sigmoid_to_scores: false\n",
        "        conv_hyperparams {\n",
        "          activation: RELU_6,\n",
        "          regularizer {\n",
        "            l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "          }\n",
        "          initializer {\n",
        "            truncated_normal_initializer {\n",
        "              stddev: 0.03\n",
        "              mean: 0.0\n",
        "            }\n",
        "          }\n",
        "          batch_norm {\n",
        "            train: true,\n",
        "            scale: true,\n",
        "            center: true,\n",
        "            decay: 0.9997,\n",
        "            epsilon: 0.001,\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    feature_extractor {\n",
        "      type: 'ssd_mobilenet_v2'\n",
        "      min_depth: 16\n",
        "      depth_multiplier: 1.0\n",
        "      conv_hyperparams {\n",
        "        activation: RELU_6,\n",
        "        regularizer {\n",
        "          l2_regularizer {\n",
        "            # weight: 0.00004\n",
        "            weight: 0.001 # higher regularizition to counter overfitting\n",
        "          }\n",
        "        }\n",
        "        initializer {\n",
        "          truncated_normal_initializer {\n",
        "            stddev: 0.03\n",
        "            mean: 0.0\n",
        "          }\n",
        "        }\n",
        "        batch_norm {\n",
        "          train: true,\n",
        "          scale: true,\n",
        "          center: true,\n",
        "          decay: 0.9997,\n",
        "          epsilon: 0.001,\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "    loss {\n",
        "      classification_loss {\n",
        "        weighted_sigmoid {\n",
        "        }\n",
        "      }\n",
        "      localization_loss {\n",
        "        weighted_smooth_l1 {\n",
        "        }\n",
        "      }\n",
        "      hard_example_miner {\n",
        "        num_hard_examples: 3000 \n",
        "        iou_threshold: 0.95\n",
        "        loss_type: CLASSIFICATION\n",
        "        max_negatives_per_positive: 3\n",
        "        min_negatives_per_image: 3\n",
        "      }\n",
        "      classification_weight: 1.0\n",
        "      localization_weight: 1.0\n",
        "    }\n",
        "    normalize_loss_by_num_matches: true\n",
        "    post_processing {\n",
        "      batch_non_max_suppression {\n",
        "        score_threshold: 1e-8\n",
        "        iou_threshold: 0.6\n",
        "        \n",
        "        #adjust this to the max number of objects per class. \n",
        "        # ex, in my case, i have one pistol in most of the images.\n",
        "        # . there are some images with more than one up to 16.\n",
        "        max_detections_per_class: 16\n",
        "        # max number of detections among all classes. I have 1 class only so\n",
        "        max_total_detections: 16\n",
        "      }\n",
        "      score_converter: SIGMOID\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_config: {\n",
        "  batch_size: 16 # training batch size\n",
        "  optimizer {\n",
        "    rms_prop_optimizer: {\n",
        "      learning_rate: {\n",
        "        exponential_decay_learning_rate {\n",
        "          initial_learning_rate: 0.003\n",
        "          decay_steps: 800720\n",
        "          decay_factor: 0.95\n",
        "        }\n",
        "      }\n",
        "      momentum_optimizer_value: 0.9\n",
        "      decay: 0.9\n",
        "      epsilon: 1.0\n",
        "    }\n",
        "  }\n",
        "\n",
        "  #the path to the pretrained model. \n",
        "  fine_tune_checkpoint: \"/content/gun_detection/models/research/pretrained_model/model.ckpt\"\n",
        "  fine_tune_checkpoint_type:  \"detection\"\n",
        "  # Note: The below line limits the training process to 200K steps, which we\n",
        "  # empirically found to be sufficient enough to train the pets dataset. This\n",
        "  # effectively bypasses the learning rate schedule (the learning rate will\n",
        "  # never decay). Remove the below line to train indefinitely.\n",
        "  num_steps: 200000 \n",
        "  \n",
        "\n",
        "  #data augmentaion is done here, you can remove or add more.\n",
        "  # They will help the model generalize but the training time will increase greatly by using more data augmentation.\n",
        "  # Check this link to add more image augmentation: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
        "  \n",
        "  data_augmentation_options {\n",
        "    random_horizontal_flip {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    random_adjust_contrast {\n",
        "    }\n",
        "  }\n",
        "  data_augmentation_options {\n",
        "    ssd_random_crop {\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "train_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "    #path to the training TFRecord\n",
        "    input_path: \"/content/gun_detection/data/train_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "}\n",
        "\n",
        "eval_config: {\n",
        "  # the number of images in your \"testing\" data (was 600 but we removed one above :) )\n",
        "  num_examples: 599\n",
        "  # the number of images to disply in Tensorboard while training\n",
        "  num_visualizations: 20\n",
        "\n",
        "  # Note: The below line limits the evaluation process to 10 evaluations.\n",
        "  # Remove the below line to evaluate indefinitely.\n",
        "  #max_evals: 10\n",
        "}\n",
        "\n",
        "eval_input_reader: {\n",
        "  tf_record_input_reader {\n",
        "      \n",
        "    #path to the testing TFRecord\n",
        "    input_path: \"/content/gun_detection/data/test_labels.record\"\n",
        "  }\n",
        "  #path to the label map \n",
        "  label_map_path: \"/content/gun_detection/data/label_map.pbtxt\"\n",
        "  shuffle: false\n",
        "  num_readers: 1\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting /content/gun_detection/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuXXZLVEG8sO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# where the model will be saved at each checkpoint while training \n",
        "model_dir = 'training/'\n",
        "\n",
        "# Optionally: remove content in output model directory to fresh start.\n",
        "!rm -rf {model_dir}\n",
        "os.makedirs(model_dir, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vAGvftxHu8K",
        "colab_type": "text"
      },
      "source": [
        "## Tensorboard\n",
        "1. Downlaoding and unzipping Tensorboard\n",
        "2. creating a link to visualize multiple graph while training.\n",
        "\n",
        "\n",
        "notes: \n",
        "  1. Tensorboard will not log any files until the training starts. \n",
        "  2. a max of 20 connection per minute is allowed when using ngrok, you will not be able to access tensorboard while the model is logging."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2ucxlc5HxHL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "d0b9b312-15f5-4186-a8a1-e323eaf426b6"
      },
      "source": [
        "#downlaoding ngrok to be able to access tensorboard on google colab\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-07-15 02:32:38--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.5.95.18, 34.234.58.229, 54.236.206.131, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.5.95.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13773305 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.13M  12.1MB/s    in 1.1s    \n",
            "\n",
            "2020-07-15 02:32:39 (12.1 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13773305/13773305]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w9ufxr7IAdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the logs that are created while training \n",
        "LOG_DIR = model_dir\n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR)\n",
        ")\n",
        "get_ipython().system_raw('./ngrok http 6006 &')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idsi9zyNIIsr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "46af4b90-c107-4a51-a15a-bafba3fda4a3"
      },
      "source": [
        "#The link to tensorboard.\n",
        "#works after the training starts.\n",
        "\n",
        "### note: if you didnt get a link as output, rerun this cell and the one above\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://038db6fe1b1b.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuJcAPZFIfu7",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "Finally training the model!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnKt6g0_IgOe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b5282b3-620e-4fa4-a92f-e5d492e9351e"
      },
      "source": [
        "\n",
        "!python3 /content/gun_detection/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={model_pipline}\\\n",
        "    --model_dir={model_dir} \\\n",
        "    --alsologtostderr \\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
            "W0715 02:33:26.368053 140574593738624 model_lib.py:758] Forced number of epochs for all eval validations to be 1.\n",
            "INFO:tensorflow:Maybe overwriting train_steps: None\n",
            "I0715 02:33:26.368298 140574593738624 config_util.py:552] Maybe overwriting train_steps: None\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0715 02:33:26.368433 140574593738624 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "I0715 02:33:26.368562 140574593738624 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: 1\n",
            "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
            "I0715 02:33:26.368722 140574593738624 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
            "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "W0715 02:33:26.368922 140574593738624 model_lib.py:774] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
            "INFO:tensorflow:create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "I0715 02:33:26.369074 140574593738624 model_lib.py:809] create_estimator_and_inputs: use_tpu False, export_to_tpu None\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9a9b0b128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "I0715 02:33:26.369556 140574593738624 estimator.py:212] Using config: {'_model_dir': 'training/', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fd9a9b0b128>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fd9a9b01f28>) includes params argument, but params are not passed to Estimator.\n",
            "W0715 02:33:26.370422 140574593738624 model_fn.py:630] Estimator's model_fn (<function create_model_fn.<locals>.model_fn at 0x7fd9a9b01f28>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Not using Distribute Coordinator.\n",
            "I0715 02:33:26.371159 140574593738624 estimator_training.py:186] Not using Distribute Coordinator.\n",
            "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
            "I0715 02:33:26.371400 140574593738624 training.py:612] Running training and evaluation locally (non-distributed).\n",
            "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "I0715 02:33:26.371744 140574593738624 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "W0715 02:33:26.383967 140574593738624 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0715 02:33:26.425096 140574593738624 dataset_builder.py:83] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "W0715 02:33:26.431775 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0715 02:33:26.457689 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/builders/dataset_builder.py:175: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd9a9b0bc88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 02:33:26.502899 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd9a9b0bc88>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9cfc32ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 02:33:26.750993 140574593738624 ag_logging.py:146] Entity <function train_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9cfc32ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "W0715 02:33:26.758253 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:80: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0715 02:33:26.766967 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/ops.py:493: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "W0715 02:33:26.911375 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0715 02:33:28.002930 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/inputs.py:261: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 02:33:28.613027 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0715 02:33:28.951096 140574593738624 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim/layers/layers.py:1089: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.402052 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.451405 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.500279 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.548875 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.603897 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:33:32.654882 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0715 02:33:38.993387 140574593738624 deprecation.py:506] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 02:33:46.759086 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "I0715 02:33:46.760710 140574593738624 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 02:33:50.966535 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 02:33:50.979493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-07-15 02:33:50.979858: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16ede540 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 02:33:50.979895: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-07-15 02:33:50.985387: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-07-15 02:33:51.112171: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:51.113199: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x16ede700 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-07-15 02:33:51.113243: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2020-07-15 02:33:51.114646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:51.115471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 02:33:51.115905: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 02:33:51.341052: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 02:33:51.509598: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 02:33:51.532400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 02:33:51.816406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 02:33:51.836782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 02:33:52.343557: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 02:33:52.343897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:52.344803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:52.345508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 02:33:52.349064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 02:33:52.350939: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 02:33:52.350980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 02:33:52.351004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 02:33:52.352260: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:52.353105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:33:52.353835: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-07-15 02:33:52.353897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 02:34:02.017170 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 02:34:02.435358 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into training/model.ckpt.\n",
            "I0715 02:34:14.594635 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 0 into training/model.ckpt.\n",
            "2020-07-15 02:34:28.481976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 02:34:32.645571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "INFO:tensorflow:loss = 13.111389, step = 0\n",
            "I0715 02:34:36.076546 140574593738624 basic_session_run_hooks.py:262] loss = 13.111389, step = 0\n",
            "INFO:tensorflow:global_step/sec: 1.35476\n",
            "I0715 02:35:49.889971 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.35476\n",
            "INFO:tensorflow:loss = 7.6554193, step = 100 (73.815 sec)\n",
            "I0715 02:35:49.891463 140574593738624 basic_session_run_hooks.py:260] loss = 7.6554193, step = 100 (73.815 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46335\n",
            "I0715 02:36:58.226504 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.46335\n",
            "INFO:tensorflow:loss = 7.1212535, step = 200 (68.336 sec)\n",
            "I0715 02:36:58.227785 140574593738624 basic_session_run_hooks.py:260] loss = 7.1212535, step = 200 (68.336 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50586\n",
            "I0715 02:38:04.633790 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.50586\n",
            "INFO:tensorflow:loss = 8.338853, step = 300 (66.412 sec)\n",
            "I0715 02:38:04.639642 140574593738624 basic_session_run_hooks.py:260] loss = 8.338853, step = 300 (66.412 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.4408\n",
            "I0715 02:39:14.039788 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.4408\n",
            "INFO:tensorflow:loss = 6.5546594, step = 400 (69.402 sec)\n",
            "I0715 02:39:14.041178 140574593738624 basic_session_run_hooks.py:260] loss = 6.5546594, step = 400 (69.402 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46041\n",
            "I0715 02:40:22.513784 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.46041\n",
            "INFO:tensorflow:loss = 6.158884, step = 500 (68.474 sec)\n",
            "I0715 02:40:22.515145 140574593738624 basic_session_run_hooks.py:260] loss = 6.158884, step = 500 (68.474 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44213\n",
            "I0715 02:41:31.855669 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.44213\n",
            "INFO:tensorflow:loss = 6.215342, step = 600 (69.342 sec)\n",
            "I0715 02:41:31.857176 140574593738624 basic_session_run_hooks.py:260] loss = 6.215342, step = 600 (69.342 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45762\n",
            "I0715 02:42:40.460608 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.45762\n",
            "INFO:tensorflow:loss = 6.078882, step = 700 (68.605 sec)\n",
            "I0715 02:42:40.462173 140574593738624 basic_session_run_hooks.py:260] loss = 6.078882, step = 700 (68.605 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49684\n",
            "I0715 02:43:47.267917 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49684\n",
            "INFO:tensorflow:loss = 6.491453, step = 800 (66.807 sec)\n",
            "I0715 02:43:47.269449 140574593738624 basic_session_run_hooks.py:260] loss = 6.491453, step = 800 (66.807 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 844 into training/model.ckpt.\n",
            "I0715 02:44:17.226500 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 844 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd99115f7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 02:44:19.026315 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd99115f7b8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd99115e158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 02:44:19.267755 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd99115e158> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 02:44:19.933446 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.706481 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.759413 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.799435 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.850281 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.893035 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:44:22.936500 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "W0715 02:44:23.807553 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/eval_util.py:855: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "W0715 02:44:24.097150 140574593738624 deprecation.py:323] From /content/gun_detection/models/research/object_detection/utils/visualization_utils.py:618: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "tf.py_func is deprecated in TF V2. Instead, there are two\n",
            "    options available in V2.\n",
            "    - tf.py_function takes a python function which manipulates tf eager\n",
            "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
            "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
            "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
            "    being differentiable using a gradient tape.\n",
            "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
            "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
            "    stateful argument making all functions stateful.\n",
            "    \n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 02:44:24.871789 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T02:44:24Z\n",
            "I0715 02:44:24.893085 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T02:44:24Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 02:44:25.433110 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 02:44:25.434467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:44:25.435165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 02:44:25.435313: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 02:44:25.435354: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 02:44:25.435398: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 02:44:25.435436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 02:44:25.435476: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 02:44:25.435521: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 02:44:25.435580: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 02:44:25.435750: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:44:25.436381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:44:25.436910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 02:44:25.437045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 02:44:25.437070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 02:44:25.437086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 02:44:25.437236: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:44:25.437852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:44:25.438338: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-844\n",
            "I0715 02:44:25.439560 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-844\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 02:44:26.396481 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 02:44:26.524151 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 02:44:59.789963 140572435961600 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 02:44:59.791395 140572435961600 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0715 02:44:59.799267 140572435961600 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.53s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.231\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.331\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.238\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.296\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.285\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.339\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.349\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.449\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-02:45:01\n",
            "I0715 02:45:01.609177 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-02:45:01\n",
            "INFO:tensorflow:Saving dict for global step 844: DetectionBoxes_Precision/mAP = 0.2310049, DetectionBoxes_Precision/mAP (large) = 0.29620582, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.33138612, DetectionBoxes_Precision/mAP@.75IOU = 0.23762962, DetectionBoxes_Recall/AR@1 = 0.28457224, DetectionBoxes_Recall/AR@10 = 0.33941093, DetectionBoxes_Recall/AR@100 = 0.34908837, DetectionBoxes_Recall/AR@100 (large) = 0.44927797, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.145414, Loss/localization_loss = 2.2859216, Loss/regularization_loss = 1.065533, Loss/total_loss = 8.496866, global_step = 844, learning_rate = 0.003, loss = 8.496866\n",
            "I0715 02:45:01.609558 140574593738624 estimator.py:2049] Saving dict for global step 844: DetectionBoxes_Precision/mAP = 0.2310049, DetectionBoxes_Precision/mAP (large) = 0.29620582, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.33138612, DetectionBoxes_Precision/mAP@.75IOU = 0.23762962, DetectionBoxes_Recall/AR@1 = 0.28457224, DetectionBoxes_Recall/AR@10 = 0.33941093, DetectionBoxes_Recall/AR@100 = 0.34908837, DetectionBoxes_Recall/AR@100 (large) = 0.44927797, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.145414, Loss/localization_loss = 2.2859216, Loss/regularization_loss = 1.065533, Loss/total_loss = 8.496866, global_step = 844, learning_rate = 0.003, loss = 8.496866\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 844: training/model.ckpt-844\n",
            "I0715 02:45:02.629488 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 844: training/model.ckpt-844\n",
            "INFO:tensorflow:global_step/sec: 0.878625\n",
            "I0715 02:45:41.082084 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.878625\n",
            "INFO:tensorflow:loss = 5.9591064, step = 900 (113.814 sec)\n",
            "I0715 02:45:41.083252 140574593738624 basic_session_run_hooks.py:260] loss = 5.9591064, step = 900 (113.814 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.41421\n",
            "I0715 02:46:51.793233 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.41421\n",
            "INFO:tensorflow:loss = 4.7816205, step = 1000 (70.712 sec)\n",
            "I0715 02:46:51.794775 140574593738624 basic_session_run_hooks.py:260] loss = 4.7816205, step = 1000 (70.712 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.53102\n",
            "I0715 02:47:57.108996 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.53102\n",
            "INFO:tensorflow:loss = 6.8830633, step = 1100 (65.316 sec)\n",
            "I0715 02:47:57.110500 140574593738624 basic_session_run_hooks.py:260] loss = 6.8830633, step = 1100 (65.316 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45311\n",
            "I0715 02:49:05.927087 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.45311\n",
            "INFO:tensorflow:loss = 6.1922374, step = 1200 (68.818 sec)\n",
            "I0715 02:49:05.928479 140574593738624 basic_session_run_hooks.py:260] loss = 6.1922374, step = 1200 (68.818 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44279\n",
            "I0715 02:50:15.237096 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.44279\n",
            "INFO:tensorflow:loss = 5.571753, step = 1300 (69.310 sec)\n",
            "I0715 02:50:15.238347 140574593738624 basic_session_run_hooks.py:260] loss = 5.571753, step = 1300 (69.310 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49013\n",
            "I0715 02:51:22.345575 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49013\n",
            "INFO:tensorflow:loss = 5.7647533, step = 1400 (67.109 sec)\n",
            "I0715 02:51:22.346859 140574593738624 basic_session_run_hooks.py:260] loss = 5.7647533, step = 1400 (67.109 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51021\n",
            "I0715 02:52:28.561348 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51021\n",
            "INFO:tensorflow:loss = 6.0184402, step = 1500 (66.216 sec)\n",
            "I0715 02:52:28.562972 140574593738624 basic_session_run_hooks.py:260] loss = 6.0184402, step = 1500 (66.216 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45768\n",
            "I0715 02:53:37.163294 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.45768\n",
            "INFO:tensorflow:loss = 5.8708963, step = 1600 (68.602 sec)\n",
            "I0715 02:53:37.164517 140574593738624 basic_session_run_hooks.py:260] loss = 5.8708963, step = 1600 (68.602 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1658 into training/model.ckpt.\n",
            "I0715 02:54:17.568646 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 1658 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd942cc2780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 02:54:19.348496 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd942cc2780>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9429d17b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 02:54:19.606539 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9429d17b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 02:54:20.252304 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.009613 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.047647 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.086125 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.124439 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.163278 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 02:54:23.201395 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 02:54:25.091791 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T02:54:25Z\n",
            "I0715 02:54:25.113224 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T02:54:25Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 02:54:25.647749 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 02:54:25.648563: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:54:25.649268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 02:54:25.649432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 02:54:25.649478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 02:54:25.649525: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 02:54:25.649595: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 02:54:25.649648: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 02:54:25.649688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 02:54:25.649750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 02:54:25.649890: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:54:25.650535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:54:25.651104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 02:54:25.651163: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 02:54:25.651184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 02:54:25.651200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 02:54:25.651406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:54:25.652488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 02:54:25.653201: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-1658\n",
            "I0715 02:54:25.655939 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-1658\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 02:54:26.587572 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 02:54:26.747530 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 02:55:01.875065 140572435961600 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 02:55:01.877078 140572435961600 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0715 02:55:01.883726 140572435961600 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.57s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.252\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.349\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.258\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.324\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-02:55:03\n",
            "I0715 02:55:03.734321 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-02:55:03\n",
            "INFO:tensorflow:Saving dict for global step 1658: DetectionBoxes_Precision/mAP = 0.25201005, DetectionBoxes_Precision/mAP (large) = 0.32403612, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.34884694, DetectionBoxes_Precision/mAP@.75IOU = 0.25823343, DetectionBoxes_Recall/AR@1 = 0.28835905, DetectionBoxes_Recall/AR@10 = 0.32398316, DetectionBoxes_Recall/AR@100 = 0.34642357, DetectionBoxes_Recall/AR@100 (large) = 0.44584838, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1910434, Loss/localization_loss = 2.2142508, Loss/regularization_loss = 1.0308586, Loss/total_loss = 8.436146, global_step = 1658, learning_rate = 0.003, loss = 8.436146\n",
            "I0715 02:55:03.734705 140574593738624 estimator.py:2049] Saving dict for global step 1658: DetectionBoxes_Precision/mAP = 0.25201005, DetectionBoxes_Precision/mAP (large) = 0.32403612, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.34884694, DetectionBoxes_Precision/mAP@.75IOU = 0.25823343, DetectionBoxes_Recall/AR@1 = 0.28835905, DetectionBoxes_Recall/AR@10 = 0.32398316, DetectionBoxes_Recall/AR@100 = 0.34642357, DetectionBoxes_Recall/AR@100 (large) = 0.44584838, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1910434, Loss/localization_loss = 2.2142508, Loss/regularization_loss = 1.0308586, Loss/total_loss = 8.436146, global_step = 1658, learning_rate = 0.003, loss = 8.436146\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1658: training/model.ckpt-1658\n",
            "I0715 02:55:03.738396 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 1658: training/model.ckpt-1658\n",
            "INFO:tensorflow:global_step/sec: 0.859545\n",
            "I0715 02:55:33.503880 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.859545\n",
            "INFO:tensorflow:loss = 6.387645, step = 1700 (116.341 sec)\n",
            "I0715 02:55:33.505037 140574593738624 basic_session_run_hooks.py:260] loss = 6.387645, step = 1700 (116.341 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49799\n",
            "I0715 02:56:40.260080 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49799\n",
            "INFO:tensorflow:loss = 5.050068, step = 1800 (66.756 sec)\n",
            "I0715 02:56:40.261472 140574593738624 basic_session_run_hooks.py:260] loss = 5.050068, step = 1800 (66.756 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47973\n",
            "I0715 02:57:47.840116 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.47973\n",
            "INFO:tensorflow:loss = 5.0972257, step = 1900 (67.580 sec)\n",
            "I0715 02:57:47.841716 140574593738624 basic_session_run_hooks.py:260] loss = 5.0972257, step = 1900 (67.580 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48849\n",
            "I0715 02:58:55.022399 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48849\n",
            "INFO:tensorflow:loss = 6.260152, step = 2000 (67.182 sec)\n",
            "I0715 02:58:55.023826 140574593738624 basic_session_run_hooks.py:260] loss = 6.260152, step = 2000 (67.182 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49771\n",
            "I0715 03:00:01.791078 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49771\n",
            "INFO:tensorflow:loss = 7.2354045, step = 2100 (66.769 sec)\n",
            "I0715 03:00:01.792724 140574593738624 basic_session_run_hooks.py:260] loss = 7.2354045, step = 2100 (66.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44182\n",
            "I0715 03:01:11.148071 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.44182\n",
            "INFO:tensorflow:loss = 6.417576, step = 2200 (69.357 sec)\n",
            "I0715 03:01:11.149469 140574593738624 basic_session_run_hooks.py:260] loss = 6.417576, step = 2200 (69.357 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.53987\n",
            "I0715 03:02:16.088819 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.53987\n",
            "INFO:tensorflow:loss = 7.518834, step = 2300 (64.941 sec)\n",
            "I0715 03:02:16.090305 140574593738624 basic_session_run_hooks.py:260] loss = 7.518834, step = 2300 (64.941 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49109\n",
            "I0715 03:03:23.153949 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49109\n",
            "INFO:tensorflow:loss = 5.711341, step = 2400 (67.065 sec)\n",
            "I0715 03:03:23.155271 140574593738624 basic_session_run_hooks.py:260] loss = 5.711341, step = 2400 (67.065 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 2482 into training/model.ckpt.\n",
            "I0715 03:04:17.665572 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 2482 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd943dcf4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 03:04:19.377494 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd943dcf4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd943c007b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 03:04:20.030083 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd943c007b8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 03:04:20.683513 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.398931 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.437818 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.476291 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.519860 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.564490 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:04:23.604610 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 03:04:25.500258 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T03:04:25Z\n",
            "I0715 03:04:25.522410 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T03:04:25Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 03:04:26.089191 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 03:04:26.090196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:04:26.090927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 03:04:26.091093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 03:04:26.091170: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 03:04:26.091244: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 03:04:26.091316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 03:04:26.091374: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 03:04:26.091450: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 03:04:26.091502: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 03:04:26.091671: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:04:26.092351: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:04:26.092898: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 03:04:26.093032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 03:04:26.093060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 03:04:26.093086: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 03:04:26.093299: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:04:26.093950: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:04:26.094609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-2482\n",
            "I0715 03:04:26.096081 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-2482\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 03:04:27.063518 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 03:04:27.209216 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 03:05:02.170351 140572444354304 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 03:05:02.172610 140572444354304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0715 03:05:02.183573 140572444354304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.17s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.160\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.162\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.207\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.291\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.327\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.360\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.463\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-03:05:03\n",
            "I0715 03:05:03.975928 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-03:05:03\n",
            "INFO:tensorflow:Saving dict for global step 2482: DetectionBoxes_Precision/mAP = 0.1602114, DetectionBoxes_Precision/mAP (large) = 0.20692013, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.25918278, DetectionBoxes_Precision/mAP@.75IOU = 0.16170046, DetectionBoxes_Recall/AR@1 = 0.2908836, DetectionBoxes_Recall/AR@10 = 0.32650772, DetectionBoxes_Recall/AR@100 = 0.3598878, DetectionBoxes_Recall/AR@100 (large) = 0.4631769, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1741743, Loss/localization_loss = 2.1727633, Loss/regularization_loss = 0.9975525, Loss/total_loss = 8.344493, global_step = 2482, learning_rate = 0.003, loss = 8.344493\n",
            "I0715 03:05:03.976385 140574593738624 estimator.py:2049] Saving dict for global step 2482: DetectionBoxes_Precision/mAP = 0.1602114, DetectionBoxes_Precision/mAP (large) = 0.20692013, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.25918278, DetectionBoxes_Precision/mAP@.75IOU = 0.16170046, DetectionBoxes_Recall/AR@1 = 0.2908836, DetectionBoxes_Recall/AR@10 = 0.32650772, DetectionBoxes_Recall/AR@100 = 0.3598878, DetectionBoxes_Recall/AR@100 (large) = 0.4631769, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1741743, Loss/localization_loss = 2.1727633, Loss/regularization_loss = 0.9975525, Loss/total_loss = 8.344493, global_step = 2482, learning_rate = 0.003, loss = 8.344493\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2482: training/model.ckpt-2482\n",
            "I0715 03:05:03.980472 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 2482: training/model.ckpt-2482\n",
            "INFO:tensorflow:global_step/sec: 0.879621\n",
            "I0715 03:05:16.839246 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.879621\n",
            "INFO:tensorflow:loss = 6.280524, step = 2500 (113.685 sec)\n",
            "I0715 03:05:16.840675 140574593738624 basic_session_run_hooks.py:260] loss = 6.280524, step = 2500 (113.685 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.52136\n",
            "I0715 03:06:22.570241 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.52136\n",
            "INFO:tensorflow:loss = 5.3050647, step = 2600 (65.731 sec)\n",
            "I0715 03:06:22.572038 140574593738624 basic_session_run_hooks.py:260] loss = 5.3050647, step = 2600 (65.731 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48276\n",
            "I0715 03:07:30.012033 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48276\n",
            "INFO:tensorflow:loss = 4.8208084, step = 2700 (67.443 sec)\n",
            "I0715 03:07:30.014953 140574593738624 basic_session_run_hooks.py:260] loss = 4.8208084, step = 2700 (67.443 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.5408\n",
            "I0715 03:08:34.913314 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.5408\n",
            "INFO:tensorflow:loss = 5.2917194, step = 2800 (64.900 sec)\n",
            "I0715 03:08:34.914880 140574593738624 basic_session_run_hooks.py:260] loss = 5.2917194, step = 2800 (64.900 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.49446\n",
            "I0715 03:09:41.827015 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.49446\n",
            "INFO:tensorflow:loss = 6.0778217, step = 2900 (66.913 sec)\n",
            "I0715 03:09:41.828064 140574593738624 basic_session_run_hooks.py:260] loss = 6.0778217, step = 2900 (66.913 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51513\n",
            "I0715 03:10:47.828081 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51513\n",
            "INFO:tensorflow:loss = 5.637057, step = 3000 (66.003 sec)\n",
            "I0715 03:10:47.831203 140574593738624 basic_session_run_hooks.py:260] loss = 5.637057, step = 3000 (66.003 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48802\n",
            "I0715 03:11:55.031401 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48802\n",
            "INFO:tensorflow:loss = 5.820693, step = 3100 (67.202 sec)\n",
            "I0715 03:11:55.032702 140574593738624 basic_session_run_hooks.py:260] loss = 5.820693, step = 3100 (67.202 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.43379\n",
            "I0715 03:13:04.776795 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.43379\n",
            "INFO:tensorflow:loss = 5.5428095, step = 3200 (69.746 sec)\n",
            "I0715 03:13:04.778261 140574593738624 basic_session_run_hooks.py:260] loss = 5.5428095, step = 3200 (69.746 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51783\n",
            "I0715 03:14:10.660494 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51783\n",
            "INFO:tensorflow:loss = 5.874735, step = 3300 (65.883 sec)\n",
            "I0715 03:14:10.661674 140574593738624 basic_session_run_hooks.py:260] loss = 5.874735, step = 3300 (65.883 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3313 into training/model.ckpt.\n",
            "I0715 03:14:18.488499 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 3313 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd94643b4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 03:14:20.417518 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd94643b4e0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd945be89d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 03:14:20.636164 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd945be89d8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 03:14:21.317415 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.393688 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.438203 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.477851 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.517828 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.555649 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:14:24.594573 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 03:14:26.394970 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T03:14:26Z\n",
            "I0715 03:14:26.415706 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T03:14:26Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 03:14:26.957987 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 03:14:26.958861: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:14:26.959445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 03:14:26.959556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 03:14:26.959624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 03:14:26.959679: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 03:14:26.959737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 03:14:26.959778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 03:14:26.959825: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 03:14:26.959872: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 03:14:26.960024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:14:26.960698: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:14:26.961222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 03:14:26.961294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 03:14:26.961315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 03:14:26.961330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 03:14:26.961484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:14:26.962140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:14:26.962712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-3313\n",
            "I0715 03:14:26.964086 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-3313\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 03:14:27.995243 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 03:14:28.155404 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 03:15:01.110508 140572435961600 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 03:15:01.112432 140572435961600 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.00s)\n",
            "I0715 03:15:01.117369 140572435961600 coco_tools.py:138] DONE (t=0.00s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.52s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.186\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.289\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.289\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.325\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.445\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-03:15:02\n",
            "I0715 03:15:02.944041 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-03:15:02\n",
            "INFO:tensorflow:Saving dict for global step 3313: DetectionBoxes_Precision/mAP = 0.1859777, DetectionBoxes_Precision/mAP (large) = 0.23959601, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.28894386, DetectionBoxes_Precision/mAP@.75IOU = 0.1925883, DetectionBoxes_Recall/AR@1 = 0.28934082, DetectionBoxes_Recall/AR@10 = 0.32496494, DetectionBoxes_Recall/AR@100 = 0.34600282, DetectionBoxes_Recall/AR@100 (large) = 0.44530687, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1583366, Loss/localization_loss = 2.0812256, Loss/regularization_loss = 0.9658556, Loss/total_loss = 8.205421, global_step = 3313, learning_rate = 0.003, loss = 8.205421\n",
            "I0715 03:15:02.944347 140574593738624 estimator.py:2049] Saving dict for global step 3313: DetectionBoxes_Precision/mAP = 0.1859777, DetectionBoxes_Precision/mAP (large) = 0.23959601, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.28894386, DetectionBoxes_Precision/mAP@.75IOU = 0.1925883, DetectionBoxes_Recall/AR@1 = 0.28934082, DetectionBoxes_Recall/AR@10 = 0.32496494, DetectionBoxes_Recall/AR@100 = 0.34600282, DetectionBoxes_Recall/AR@100 (large) = 0.44530687, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.1583366, Loss/localization_loss = 2.0812256, Loss/regularization_loss = 0.9658556, Loss/total_loss = 8.205421, global_step = 3313, learning_rate = 0.003, loss = 8.205421\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3313: training/model.ckpt-3313\n",
            "I0715 03:15:02.948224 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 3313: training/model.ckpt-3313\n",
            "INFO:tensorflow:global_step/sec: 0.89497\n",
            "I0715 03:16:02.396042 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.89497\n",
            "INFO:tensorflow:loss = 5.419029, step = 3400 (111.736 sec)\n",
            "I0715 03:16:02.397636 140574593738624 basic_session_run_hooks.py:260] loss = 5.419029, step = 3400 (111.736 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.55216\n",
            "I0715 03:17:06.822433 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.55216\n",
            "INFO:tensorflow:loss = 5.2188187, step = 3500 (64.426 sec)\n",
            "I0715 03:17:06.823811 140574593738624 basic_session_run_hooks.py:260] loss = 5.2188187, step = 3500 (64.426 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48212\n",
            "I0715 03:18:14.293540 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48212\n",
            "INFO:tensorflow:loss = 5.3901553, step = 3600 (67.472 sec)\n",
            "I0715 03:18:14.295686 140574593738624 basic_session_run_hooks.py:260] loss = 5.3901553, step = 3600 (67.472 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46639\n",
            "I0715 03:19:22.487987 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.46639\n",
            "INFO:tensorflow:loss = 5.6025395, step = 3700 (68.194 sec)\n",
            "I0715 03:19:22.489324 140574593738624 basic_session_run_hooks.py:260] loss = 5.6025395, step = 3700 (68.194 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51026\n",
            "I0715 03:20:28.701727 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51026\n",
            "INFO:tensorflow:loss = 5.058302, step = 3800 (66.214 sec)\n",
            "I0715 03:20:28.703277 140574593738624 basic_session_run_hooks.py:260] loss = 5.058302, step = 3800 (66.214 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51992\n",
            "I0715 03:21:34.494490 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51992\n",
            "INFO:tensorflow:loss = 4.311313, step = 3900 (65.793 sec)\n",
            "I0715 03:21:34.496060 140574593738624 basic_session_run_hooks.py:260] loss = 4.311313, step = 3900 (65.793 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.47028\n",
            "I0715 03:22:42.508557 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.47028\n",
            "INFO:tensorflow:loss = 5.9225864, step = 4000 (68.014 sec)\n",
            "I0715 03:22:42.510149 140574593738624 basic_session_run_hooks.py:260] loss = 5.9225864, step = 4000 (68.014 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50166\n",
            "I0715 03:23:49.101716 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.50166\n",
            "INFO:tensorflow:loss = 5.340373, step = 4100 (66.593 sec)\n",
            "I0715 03:23:49.103055 140574593738624 basic_session_run_hooks.py:260] loss = 5.340373, step = 4100 (66.593 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4146 into training/model.ckpt.\n",
            "I0715 03:24:19.100366 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 4146 into training/model.ckpt.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "W0715 03:24:19.209130 140574593738624 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd946448a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 03:24:20.851012 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd946448a58>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9428548c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 03:24:21.067129 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd9428548c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 03:24:21.695488 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.451991 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.490490 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.538034 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.587295 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.647957 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:24:24.688727 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 03:24:26.858131 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T03:24:26Z\n",
            "I0715 03:24:26.878519 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T03:24:26Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 03:24:27.396917 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 03:24:27.397718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:24:27.398388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 03:24:27.398506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 03:24:27.398566: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 03:24:27.398655: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 03:24:27.398700: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 03:24:27.398746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 03:24:27.398798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 03:24:27.398870: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 03:24:27.399014: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:24:27.399642: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:24:27.400259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 03:24:27.400416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 03:24:27.400442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 03:24:27.400472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 03:24:27.400658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:24:27.401383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:24:27.402779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4146\n",
            "I0715 03:24:27.403987 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-4146\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 03:24:28.420912 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 03:24:28.566693 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 03:25:01.790027 140572435961600 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 03:25:01.792149 140572435961600 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0715 03:25:01.802086 140572435961600 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.50s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.19s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.158\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.280\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.157\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.203\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.288\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.323\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.345\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.444\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-03:25:03\n",
            "I0715 03:25:03.618787 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-03:25:03\n",
            "INFO:tensorflow:Saving dict for global step 4146: DetectionBoxes_Precision/mAP = 0.15776883, DetectionBoxes_Precision/mAP (large) = 0.20303953, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27960104, DetectionBoxes_Precision/mAP@.75IOU = 0.15686235, DetectionBoxes_Recall/AR@1 = 0.28779805, DetectionBoxes_Recall/AR@10 = 0.3227209, DetectionBoxes_Recall/AR@100 = 0.34474054, DetectionBoxes_Recall/AR@100 (large) = 0.4436823, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.085871, Loss/localization_loss = 2.068377, Loss/regularization_loss = 0.9354845, Loss/total_loss = 8.089719, global_step = 4146, learning_rate = 0.003, loss = 8.089719\n",
            "I0715 03:25:03.619214 140574593738624 estimator.py:2049] Saving dict for global step 4146: DetectionBoxes_Precision/mAP = 0.15776883, DetectionBoxes_Precision/mAP (large) = 0.20303953, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.27960104, DetectionBoxes_Precision/mAP@.75IOU = 0.15686235, DetectionBoxes_Recall/AR@1 = 0.28779805, DetectionBoxes_Recall/AR@10 = 0.3227209, DetectionBoxes_Recall/AR@100 = 0.34474054, DetectionBoxes_Recall/AR@100 (large) = 0.4436823, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.085871, Loss/localization_loss = 2.068377, Loss/regularization_loss = 0.9354845, Loss/total_loss = 8.089719, global_step = 4146, learning_rate = 0.003, loss = 8.089719\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4146: training/model.ckpt-4146\n",
            "I0715 03:25:03.623042 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4146: training/model.ckpt-4146\n",
            "INFO:tensorflow:global_step/sec: 0.888834\n",
            "I0715 03:25:41.608691 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.888834\n",
            "INFO:tensorflow:loss = 5.9427886, step = 4200 (112.507 sec)\n",
            "I0715 03:25:41.610058 140574593738624 basic_session_run_hooks.py:260] loss = 5.9427886, step = 4200 (112.507 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.50276\n",
            "I0715 03:26:48.152930 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.50276\n",
            "INFO:tensorflow:loss = 6.119847, step = 4300 (66.544 sec)\n",
            "I0715 03:26:48.154223 140574593738624 basic_session_run_hooks.py:260] loss = 6.119847, step = 4300 (66.544 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48212\n",
            "I0715 03:27:55.623859 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48212\n",
            "INFO:tensorflow:loss = 4.5956707, step = 4400 (67.471 sec)\n",
            "I0715 03:27:55.625230 140574593738624 basic_session_run_hooks.py:260] loss = 4.5956707, step = 4400 (67.471 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.52286\n",
            "I0715 03:29:01.289972 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.52286\n",
            "INFO:tensorflow:loss = 5.2870355, step = 4500 (65.666 sec)\n",
            "I0715 03:29:01.291433 140574593738624 basic_session_run_hooks.py:260] loss = 5.2870355, step = 4500 (65.666 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51451\n",
            "I0715 03:30:07.317730 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51451\n",
            "INFO:tensorflow:loss = 4.5233874, step = 4600 (66.028 sec)\n",
            "I0715 03:30:07.319214 140574593738624 basic_session_run_hooks.py:260] loss = 4.5233874, step = 4600 (66.028 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.46793\n",
            "I0715 03:31:15.440834 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.46793\n",
            "INFO:tensorflow:loss = 5.114584, step = 4700 (68.123 sec)\n",
            "I0715 03:31:15.442120 140574593738624 basic_session_run_hooks.py:260] loss = 5.114584, step = 4700 (68.123 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.45518\n",
            "I0715 03:32:24.160685 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.45518\n",
            "INFO:tensorflow:loss = 4.2922397, step = 4800 (68.720 sec)\n",
            "I0715 03:32:24.162374 140574593738624 basic_session_run_hooks.py:260] loss = 4.2922397, step = 4800 (68.720 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.48783\n",
            "I0715 03:33:31.372465 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.48783\n",
            "INFO:tensorflow:loss = 4.892026, step = 4900 (67.212 sec)\n",
            "I0715 03:33:31.373923 140574593738624 basic_session_run_hooks.py:260] loss = 4.892026, step = 4900 (67.212 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 4974 into training/model.ckpt.\n",
            "I0715 03:34:19.792498 140574593738624 basic_session_run_hooks.py:606] Saving checkpoints for 4974 into training/model.ckpt.\n",
            "WARNING:tensorflow:Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd990fa63c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "W0715 03:34:21.545796 140574593738624 ag_logging.py:146] Entity <bound method TfExampleDecoder.decode of <object_detection.data_decoders.tf_example_decoder.TfExampleDecoder object at 0x7fd990fa63c8>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\n",
            "WARNING:tensorflow:Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd946043ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "W0715 03:34:21.767383 140574593738624 ag_logging.py:146] Entity <function eval_input.<locals>.transform_and_pad_input_data_fn at 0x7fd946043ea0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "I0715 03:34:22.392107 140574593738624 estimator.py:1148] Calling model_fn.\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.151460 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.197037 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.244679 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.285537 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.324984 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:depth of additional conv before box predictor: 0\n",
            "I0715 03:34:25.364387 140574593738624 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "I0715 03:34:27.316495 140574593738624 estimator.py:1150] Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2020-07-15T03:34:27Z\n",
            "I0715 03:34:27.338953 140574593738624 evaluation.py:255] Starting evaluation at 2020-07-15T03:34:27Z\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "I0715 03:34:27.945782 140574593738624 monitored_session.py:240] Graph was finalized.\n",
            "2020-07-15 03:34:27.946706: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:34:27.947405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-07-15 03:34:27.947508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-07-15 03:34:27.947571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-07-15 03:34:27.947660: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-07-15 03:34:27.947716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-07-15 03:34:27.947777: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-07-15 03:34:27.947829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-07-15 03:34:27.947879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-07-15 03:34:27.948032: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:34:27.948693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:34:27.949264: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-07-15 03:34:27.949329: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-07-15 03:34:27.949357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-07-15 03:34:27.949389: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-07-15 03:34:27.949573: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:34:27.950238: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-07-15 03:34:27.950848: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10805 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "INFO:tensorflow:Restoring parameters from training/model.ckpt-4974\n",
            "I0715 03:34:27.952459 140574593738624 saver.py:1284] Restoring parameters from training/model.ckpt-4974\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "I0715 03:34:28.944339 140574593738624 session_manager.py:500] Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "I0715 03:34:29.084166 140574593738624 session_manager.py:502] Done running local_init_op.\n",
            "INFO:tensorflow:Performing evaluation on 599 images.\n",
            "I0715 03:35:02.632555 140572444354304 coco_evaluation.py:237] Performing evaluation on 599 images.\n",
            "creating index...\n",
            "index created!\n",
            "INFO:tensorflow:Loading and preparing annotation results...\n",
            "I0715 03:35:02.635056 140572444354304 coco_tools.py:116] Loading and preparing annotation results...\n",
            "INFO:tensorflow:DONE (t=0.01s)\n",
            "I0715 03:35:02.645532 140572444354304 coco_tools.py:138] DONE (t=0.01s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=1.54s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.15s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.194\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.327\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.207\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.251\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.286\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.320\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.346\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.446\n",
            "INFO:tensorflow:Finished evaluation at 2020-07-15-03:35:04\n",
            "I0715 03:35:04.441739 140574593738624 evaluation.py:275] Finished evaluation at 2020-07-15-03:35:04\n",
            "INFO:tensorflow:Saving dict for global step 4974: DetectionBoxes_Precision/mAP = 0.19354571, DetectionBoxes_Precision/mAP (large) = 0.25081083, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.32704413, DetectionBoxes_Precision/mAP@.75IOU = 0.20696522, DetectionBoxes_Recall/AR@1 = 0.28597474, DetectionBoxes_Recall/AR@10 = 0.31977558, DetectionBoxes_Recall/AR@100 = 0.34628332, DetectionBoxes_Recall/AR@100 (large) = 0.44566786, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.07874, Loss/localization_loss = 2.0149636, Loss/regularization_loss = 0.9070815, Loss/total_loss = 8.00079, global_step = 4974, learning_rate = 0.003, loss = 8.00079\n",
            "I0715 03:35:04.442075 140574593738624 estimator.py:2049] Saving dict for global step 4974: DetectionBoxes_Precision/mAP = 0.19354571, DetectionBoxes_Precision/mAP (large) = 0.25081083, DetectionBoxes_Precision/mAP (medium) = 0.0, DetectionBoxes_Precision/mAP (small) = 0.0, DetectionBoxes_Precision/mAP@.50IOU = 0.32704413, DetectionBoxes_Precision/mAP@.75IOU = 0.20696522, DetectionBoxes_Recall/AR@1 = 0.28597474, DetectionBoxes_Recall/AR@10 = 0.31977558, DetectionBoxes_Recall/AR@100 = 0.34628332, DetectionBoxes_Recall/AR@100 (large) = 0.44566786, DetectionBoxes_Recall/AR@100 (medium) = 0.0, DetectionBoxes_Recall/AR@100 (small) = 0.0, Loss/classification_loss = 5.07874, Loss/localization_loss = 2.0149636, Loss/regularization_loss = 0.9070815, Loss/total_loss = 8.00079, global_step = 4974, learning_rate = 0.003, loss = 8.00079\n",
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4974: training/model.ckpt-4974\n",
            "I0715 03:35:04.445720 140574593738624 estimator.py:2109] Saving 'checkpoint_path' summary for global step 4974: training/model.ckpt-4974\n",
            "INFO:tensorflow:global_step/sec: 0.898059\n",
            "I0715 03:35:22.723793 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 0.898059\n",
            "INFO:tensorflow:loss = 4.8149924, step = 5000 (111.351 sec)\n",
            "I0715 03:35:22.725106 140574593738624 basic_session_run_hooks.py:260] loss = 4.8149924, step = 5000 (111.351 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.51031\n",
            "I0715 03:36:28.935362 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.51031\n",
            "INFO:tensorflow:loss = 4.5876436, step = 5100 (66.212 sec)\n",
            "I0715 03:36:28.936706 140574593738624 basic_session_run_hooks.py:260] loss = 4.5876436, step = 5100 (66.212 sec)\n",
            "INFO:tensorflow:global_step/sec: 1.44739\n",
            "I0715 03:37:38.025027 140574593738624 basic_session_run_hooks.py:692] global_step/sec: 1.44739\n",
            "INFO:tensorflow:loss = 4.675748, step = 5200 (69.090 sec)\n",
            "I0715 03:37:38.026639 140574593738624 basic_session_run_hooks.py:260] loss = 4.675748, step = 5200 (69.090 sec)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPN8liiQc7Ue",
        "colab_type": "text"
      },
      "source": [
        "## Exporting The Trained model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upwUdom0lTub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "94da85d0-049c-4693-e32a-7acd1f03e57e"
      },
      "source": [
        "#the location where the exported model will be saved in.\n",
        "output_directory = '/content/gun_detection/models/research/fine_tuned_model'\n",
        "\n",
        "# goes through the model is the training/ dir and gets the last one.\n",
        "# you could choose a specfic one instead of the last\n",
        "lst = os.listdir(model_dir)\n",
        "lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n",
        "steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n",
        "last_model = lst[steps.argmax()].replace('.meta', '')\n",
        "last_model_path = os.path.join(model_dir, last_model)\n",
        "print(last_model_path)\n",
        "\n",
        "#exports the model specifed and inference graph\n",
        "!python /content/gun_detection/models/research/object_detection/export_inference_graph.py \\\n",
        "    --input_type=image_tensor \\\n",
        "    --pipeline_config_path={model_pipline} \\\n",
        "    --output_directory={output_directory} \\\n",
        "    --trained_checkpoint_prefix={last_model_path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-7ebaf32d5ca0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m'model.ckpt-'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'.meta'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mlast_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.meta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mlast_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: attempt to get argmax of an empty sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuxDnGPM_JPL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downloads the frozen model that is needed for inference\n",
        "files.download(output_directory + '/frozen_inference_graph.pb')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTkkaGq5BpYi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#downlaod the label map\n",
        "files.download(DATA_BASE_PATH + '/label_map.pbtxt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWr3WwzHL2vC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}