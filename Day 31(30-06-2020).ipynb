{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Problem Statement**\n",
    "\n",
    "The problem that we are going to solve here is that given a set of features that describe a tumour whether it is Malignant or Benign, our machine learning model must predict whether the tumour is Malignant or Benign. To train our machine learning model with tumour data, we will be using [SCLCData](https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87139402</td>\n",
       "      <td>B</td>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8910251</td>\n",
       "      <td>B</td>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>905520</td>\n",
       "      <td>B</td>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>868871</td>\n",
       "      <td>B</td>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9012568</td>\n",
       "      <td>B</td>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>911320502</td>\n",
       "      <td>B</td>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>898677</td>\n",
       "      <td>B</td>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>873885</td>\n",
       "      <td>M</td>\n",
       "      <td>15.28</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>911201</td>\n",
       "      <td>B</td>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>9012795</td>\n",
       "      <td>M</td>\n",
       "      <td>21.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id diagnosis  radius_mean  texture_mean  perimeter_mean  \\\n",
       "0     87139402         B        12.32         12.39           78.85   \n",
       "1      8910251         B        10.60         18.95           69.28   \n",
       "2       905520         B        11.04         16.83           70.92   \n",
       "3       868871         B        11.28         13.39           73.00   \n",
       "4      9012568         B        15.19         13.21           97.65   \n",
       "..         ...       ...          ...           ...             ...   \n",
       "564  911320502         B        13.17         18.22           84.28   \n",
       "565     898677         B        10.26         14.71           66.20   \n",
       "566     873885         M        15.28         22.41           98.92   \n",
       "567     911201         B        14.53         13.98           93.86   \n",
       "568    9012795         M        21.37         15.10          141.30   \n",
       "\n",
       "     area_mean  smoothness_mean  compactness_mean  concavity_mean  \\\n",
       "0        464.1          0.10280           0.06981         0.03987   \n",
       "1        346.4          0.09688           0.11470         0.06387   \n",
       "2        373.2          0.10770           0.07804         0.03046   \n",
       "3        384.8          0.11640           0.11360         0.04635   \n",
       "4        711.8          0.07963           0.06934         0.03393   \n",
       "..         ...              ...               ...             ...   \n",
       "564      537.3          0.07466           0.05994         0.04859   \n",
       "565      321.6          0.09882           0.09159         0.03581   \n",
       "566      710.6          0.09057           0.10520         0.05375   \n",
       "567      644.2          0.10990           0.09242         0.06895   \n",
       "568     1386.0          0.10010           0.15150         0.19320   \n",
       "\n",
       "     points_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0        0.03700  ...         13.50          15.64            86.97   \n",
       "1        0.02642  ...         11.88          22.94            78.28   \n",
       "2        0.02480  ...         12.41          26.44            79.93   \n",
       "3        0.04796  ...         11.92          15.77            76.53   \n",
       "4        0.02657  ...         16.20          15.73           104.50   \n",
       "..           ...  ...           ...            ...              ...   \n",
       "564      0.02870  ...         14.90          23.89            95.10   \n",
       "565      0.02037  ...         10.88          19.48            70.89   \n",
       "566      0.03263  ...         17.80          28.03           113.80   \n",
       "567      0.06495  ...         15.80          16.93           103.10   \n",
       "568      0.12550  ...         22.69          21.84           152.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         549.1            0.1385             0.1266          0.12420   \n",
       "1         424.8            0.1213             0.2515          0.19160   \n",
       "2         471.4            0.1369             0.1482          0.10670   \n",
       "3         434.0            0.1367             0.1822          0.08669   \n",
       "4         819.1            0.1126             0.1737          0.13620   \n",
       "..          ...               ...                ...              ...   \n",
       "564       687.6            0.1282             0.1965          0.18760   \n",
       "565       357.1            0.1360             0.1636          0.07162   \n",
       "566       973.1            0.1301             0.3299          0.36300   \n",
       "567       749.9            0.1347             0.1478          0.13730   \n",
       "568      1535.0            0.1192             0.2840          0.40240   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0         0.09391          0.2827          0.06771  \n",
       "1         0.07926          0.2940          0.07587  \n",
       "2         0.07431          0.2998          0.07881  \n",
       "3         0.08611          0.2102          0.06784  \n",
       "4         0.08178          0.2487          0.06766  \n",
       "..            ...             ...              ...  \n",
       "564       0.10450          0.2235          0.06925  \n",
       "565       0.04074          0.2434          0.08488  \n",
       "566       0.12260          0.3175          0.09772  \n",
       "567       0.10690          0.2606          0.07810  \n",
       "568       0.19660          0.2730          0.08666  \n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data:\n",
    "data=pd.read_csv(\"https://raw.githubusercontent.com/Mounika-Kajjam/Datasets/master/wbcd.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: diagnosis, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check the frequency of B and M\n",
    "data.diagnosis.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "diagnosis            0\n",
       "radius_mean          0\n",
       "texture_mean         0\n",
       "perimeter_mean       0\n",
       "area_mean            0\n",
       "smoothness_mean      0\n",
       "compactness_mean     0\n",
       "concavity_mean       0\n",
       "points_mean          0\n",
       "symmetry_mean        0\n",
       "dimension_mean       0\n",
       "radius_se            0\n",
       "texture_se           0\n",
       "perimeter_se         0\n",
       "area_se              0\n",
       "smoothness_se        0\n",
       "compactness_se       0\n",
       "concavity_se         0\n",
       "points_se            0\n",
       "symmetry_se          0\n",
       "dimension_se         0\n",
       "radius_worst         0\n",
       "texture_worst        0\n",
       "perimeter_worst      0\n",
       "area_worst           0\n",
       "smoothness_worst     0\n",
       "compactness_worst    0\n",
       "concavity_worst      0\n",
       "points_worst         0\n",
       "symmetry_worst       0\n",
       "dimension_worst      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking the missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the dataset into input and output--> Train and test\n",
    "#Train--> Building the model\n",
    "#Test --> How wellthe model has learnt(Generaize an unseen data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.32</td>\n",
       "      <td>12.39</td>\n",
       "      <td>78.85</td>\n",
       "      <td>464.1</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.06981</td>\n",
       "      <td>0.03987</td>\n",
       "      <td>0.03700</td>\n",
       "      <td>0.1959</td>\n",
       "      <td>0.05955</td>\n",
       "      <td>...</td>\n",
       "      <td>13.50</td>\n",
       "      <td>15.64</td>\n",
       "      <td>86.97</td>\n",
       "      <td>549.1</td>\n",
       "      <td>0.1385</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.12420</td>\n",
       "      <td>0.09391</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>0.06771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.60</td>\n",
       "      <td>18.95</td>\n",
       "      <td>69.28</td>\n",
       "      <td>346.4</td>\n",
       "      <td>0.09688</td>\n",
       "      <td>0.11470</td>\n",
       "      <td>0.06387</td>\n",
       "      <td>0.02642</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>0.06491</td>\n",
       "      <td>...</td>\n",
       "      <td>11.88</td>\n",
       "      <td>22.94</td>\n",
       "      <td>78.28</td>\n",
       "      <td>424.8</td>\n",
       "      <td>0.1213</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.19160</td>\n",
       "      <td>0.07926</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.07587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.04</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "      <td>373.2</td>\n",
       "      <td>0.10770</td>\n",
       "      <td>0.07804</td>\n",
       "      <td>0.03046</td>\n",
       "      <td>0.02480</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.06340</td>\n",
       "      <td>...</td>\n",
       "      <td>12.41</td>\n",
       "      <td>26.44</td>\n",
       "      <td>79.93</td>\n",
       "      <td>471.4</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.10670</td>\n",
       "      <td>0.07431</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>0.07881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.28</td>\n",
       "      <td>13.39</td>\n",
       "      <td>73.00</td>\n",
       "      <td>384.8</td>\n",
       "      <td>0.11640</td>\n",
       "      <td>0.11360</td>\n",
       "      <td>0.04635</td>\n",
       "      <td>0.04796</td>\n",
       "      <td>0.1771</td>\n",
       "      <td>0.06072</td>\n",
       "      <td>...</td>\n",
       "      <td>11.92</td>\n",
       "      <td>15.77</td>\n",
       "      <td>76.53</td>\n",
       "      <td>434.0</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>0.1822</td>\n",
       "      <td>0.08669</td>\n",
       "      <td>0.08611</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>0.06784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.19</td>\n",
       "      <td>13.21</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.8</td>\n",
       "      <td>0.07963</td>\n",
       "      <td>0.06934</td>\n",
       "      <td>0.03393</td>\n",
       "      <td>0.02657</td>\n",
       "      <td>0.1721</td>\n",
       "      <td>0.05544</td>\n",
       "      <td>...</td>\n",
       "      <td>16.20</td>\n",
       "      <td>15.73</td>\n",
       "      <td>104.50</td>\n",
       "      <td>819.1</td>\n",
       "      <td>0.1126</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.08178</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.06766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>13.17</td>\n",
       "      <td>18.22</td>\n",
       "      <td>84.28</td>\n",
       "      <td>537.3</td>\n",
       "      <td>0.07466</td>\n",
       "      <td>0.05994</td>\n",
       "      <td>0.04859</td>\n",
       "      <td>0.02870</td>\n",
       "      <td>0.1454</td>\n",
       "      <td>0.05549</td>\n",
       "      <td>...</td>\n",
       "      <td>14.90</td>\n",
       "      <td>23.89</td>\n",
       "      <td>95.10</td>\n",
       "      <td>687.6</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1965</td>\n",
       "      <td>0.18760</td>\n",
       "      <td>0.10450</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>0.06925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>10.26</td>\n",
       "      <td>14.71</td>\n",
       "      <td>66.20</td>\n",
       "      <td>321.6</td>\n",
       "      <td>0.09882</td>\n",
       "      <td>0.09159</td>\n",
       "      <td>0.03581</td>\n",
       "      <td>0.02037</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.07005</td>\n",
       "      <td>...</td>\n",
       "      <td>10.88</td>\n",
       "      <td>19.48</td>\n",
       "      <td>70.89</td>\n",
       "      <td>357.1</td>\n",
       "      <td>0.1360</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>0.07162</td>\n",
       "      <td>0.04074</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.08488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>15.28</td>\n",
       "      <td>22.41</td>\n",
       "      <td>98.92</td>\n",
       "      <td>710.6</td>\n",
       "      <td>0.09057</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.05375</td>\n",
       "      <td>0.03263</td>\n",
       "      <td>0.1727</td>\n",
       "      <td>0.06317</td>\n",
       "      <td>...</td>\n",
       "      <td>17.80</td>\n",
       "      <td>28.03</td>\n",
       "      <td>113.80</td>\n",
       "      <td>973.1</td>\n",
       "      <td>0.1301</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.36300</td>\n",
       "      <td>0.12260</td>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.09772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>14.53</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "      <td>644.2</td>\n",
       "      <td>0.10990</td>\n",
       "      <td>0.09242</td>\n",
       "      <td>0.06895</td>\n",
       "      <td>0.06495</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.06121</td>\n",
       "      <td>...</td>\n",
       "      <td>15.80</td>\n",
       "      <td>16.93</td>\n",
       "      <td>103.10</td>\n",
       "      <td>749.9</td>\n",
       "      <td>0.1347</td>\n",
       "      <td>0.1478</td>\n",
       "      <td>0.13730</td>\n",
       "      <td>0.10690</td>\n",
       "      <td>0.2606</td>\n",
       "      <td>0.07810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>21.37</td>\n",
       "      <td>15.10</td>\n",
       "      <td>141.30</td>\n",
       "      <td>1386.0</td>\n",
       "      <td>0.10010</td>\n",
       "      <td>0.15150</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.12550</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>0.06183</td>\n",
       "      <td>...</td>\n",
       "      <td>22.69</td>\n",
       "      <td>21.84</td>\n",
       "      <td>152.10</td>\n",
       "      <td>1535.0</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.40240</td>\n",
       "      <td>0.19660</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>0.08666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0          12.32         12.39           78.85      464.1          0.10280   \n",
       "1          10.60         18.95           69.28      346.4          0.09688   \n",
       "2          11.04         16.83           70.92      373.2          0.10770   \n",
       "3          11.28         13.39           73.00      384.8          0.11640   \n",
       "4          15.19         13.21           97.65      711.8          0.07963   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        13.17         18.22           84.28      537.3          0.07466   \n",
       "565        10.26         14.71           66.20      321.6          0.09882   \n",
       "566        15.28         22.41           98.92      710.6          0.09057   \n",
       "567        14.53         13.98           93.86      644.2          0.10990   \n",
       "568        21.37         15.10          141.30     1386.0          0.10010   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0             0.06981         0.03987      0.03700         0.1959   \n",
       "1             0.11470         0.06387      0.02642         0.1922   \n",
       "2             0.07804         0.03046      0.02480         0.1714   \n",
       "3             0.11360         0.04635      0.04796         0.1771   \n",
       "4             0.06934         0.03393      0.02657         0.1721   \n",
       "..                ...             ...          ...            ...   \n",
       "564           0.05994         0.04859      0.02870         0.1454   \n",
       "565           0.09159         0.03581      0.02037         0.1633   \n",
       "566           0.10520         0.05375      0.03263         0.1727   \n",
       "567           0.09242         0.06895      0.06495         0.1650   \n",
       "568           0.15150         0.19320      0.12550         0.1973   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.05955  ...         13.50          15.64            86.97   \n",
       "1           0.06491  ...         11.88          22.94            78.28   \n",
       "2           0.06340  ...         12.41          26.44            79.93   \n",
       "3           0.06072  ...         11.92          15.77            76.53   \n",
       "4           0.05544  ...         16.20          15.73           104.50   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "564         0.05549  ...         14.90          23.89            95.10   \n",
       "565         0.07005  ...         10.88          19.48            70.89   \n",
       "566         0.06317  ...         17.80          28.03           113.80   \n",
       "567         0.06121  ...         15.80          16.93           103.10   \n",
       "568         0.06183  ...         22.69          21.84           152.10   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0         549.1            0.1385             0.1266          0.12420   \n",
       "1         424.8            0.1213             0.2515          0.19160   \n",
       "2         471.4            0.1369             0.1482          0.10670   \n",
       "3         434.0            0.1367             0.1822          0.08669   \n",
       "4         819.1            0.1126             0.1737          0.13620   \n",
       "..          ...               ...                ...              ...   \n",
       "564       687.6            0.1282             0.1965          0.18760   \n",
       "565       357.1            0.1360             0.1636          0.07162   \n",
       "566       973.1            0.1301             0.3299          0.36300   \n",
       "567       749.9            0.1347             0.1478          0.13730   \n",
       "568      1535.0            0.1192             0.2840          0.40240   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0         0.09391          0.2827          0.06771  \n",
       "1         0.07926          0.2940          0.07587  \n",
       "2         0.07431          0.2998          0.07881  \n",
       "3         0.08611          0.2102          0.06784  \n",
       "4         0.08178          0.2487          0.06766  \n",
       "..            ...             ...              ...  \n",
       "564       0.10450          0.2235          0.06925  \n",
       "565       0.04074          0.2434          0.08488  \n",
       "566       0.12260          0.3175          0.09772  \n",
       "567       0.10690          0.2606          0.07810  \n",
       "568       0.19660          0.2730          0.08666  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preparing Input and Output\n",
    "#Droping the id and diagnosis column\n",
    "X = data.drop(['id', 'diagnosis'],axis = 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      B\n",
       "1      B\n",
       "2      B\n",
       "3      B\n",
       "4      B\n",
       "      ..\n",
       "564    B\n",
       "565    B\n",
       "566    M\n",
       "567    B\n",
       "568    M\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Accessing the Output column:\n",
    "y = data.diagnosis\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing the Training and Testing data\n",
    "#We are storing 70% of the data(569 rows) into training and the remaining 30% of the data into testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(398, 30)\n",
      "(171, 30)\n",
      "(398,)\n",
      "(171,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Before splitting if you apply standardization --> you are considering whole \n",
    "##you are including test data also into training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.0654828 , -1.35518629,  0.03134589, ..., -0.04689041,\n",
       "         0.3683001 , -1.22806684],\n",
       "       [-0.77639967, -0.1225787 , -0.77192193, ..., -0.39868555,\n",
       "         0.3648074 , -0.83648993],\n",
       "       [-0.84936282, -1.05782571, -0.87563499, ..., -1.03880764,\n",
       "        -1.65746674, -0.54459715],\n",
       "       ...,\n",
       "       [-0.88303812, -0.35998755, -0.85204535, ..., -0.1993652 ,\n",
       "        -0.98162901, -0.01313199],\n",
       "       [ 1.07854805,  0.213151  ,  0.91351698, ...,  0.10120204,\n",
       "         3.54665843, -1.20658794],\n",
       "       [-0.26846391, -0.90674734, -0.26149099, ..., -0.22037015,\n",
       "         1.74267813,  0.1823811 ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler =  StandardScaler()\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.767981</td>\n",
       "      <td>-0.055433</td>\n",
       "      <td>-0.795918</td>\n",
       "      <td>-0.721932</td>\n",
       "      <td>-0.589333</td>\n",
       "      <td>-0.996232</td>\n",
       "      <td>-0.780212</td>\n",
       "      <td>-0.661564</td>\n",
       "      <td>0.810759</td>\n",
       "      <td>-0.417646</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.785433</td>\n",
       "      <td>0.137175</td>\n",
       "      <td>-0.806874</td>\n",
       "      <td>-0.716765</td>\n",
       "      <td>-0.854530</td>\n",
       "      <td>-0.972772</td>\n",
       "      <td>-0.923478</td>\n",
       "      <td>-0.752143</td>\n",
       "      <td>0.726302</td>\n",
       "      <td>-0.720284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.116925</td>\n",
       "      <td>-0.731688</td>\n",
       "      <td>-0.158591</td>\n",
       "      <td>-0.209416</td>\n",
       "      <td>-0.875377</td>\n",
       "      <td>-0.728226</td>\n",
       "      <td>-0.760262</td>\n",
       "      <td>-0.697520</td>\n",
       "      <td>0.281483</td>\n",
       "      <td>-0.839423</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273344</td>\n",
       "      <td>-0.865993</td>\n",
       "      <td>-0.216452</td>\n",
       "      <td>-0.348722</td>\n",
       "      <td>-0.911689</td>\n",
       "      <td>-0.222689</td>\n",
       "      <td>-0.624656</td>\n",
       "      <td>-0.633669</td>\n",
       "      <td>0.824098</td>\n",
       "      <td>-0.330910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.100998</td>\n",
       "      <td>-0.544639</td>\n",
       "      <td>1.047734</td>\n",
       "      <td>0.940735</td>\n",
       "      <td>-0.426476</td>\n",
       "      <td>0.438365</td>\n",
       "      <td>0.300001</td>\n",
       "      <td>0.371772</td>\n",
       "      <td>-0.289084</td>\n",
       "      <td>-0.675726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870599</td>\n",
       "      <td>-0.559798</td>\n",
       "      <td>0.797992</td>\n",
       "      <td>0.733636</td>\n",
       "      <td>-0.216988</td>\n",
       "      <td>0.157285</td>\n",
       "      <td>0.858626</td>\n",
       "      <td>0.630104</td>\n",
       "      <td>-0.015897</td>\n",
       "      <td>-0.042321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922326</td>\n",
       "      <td>1.220340</td>\n",
       "      <td>-0.929322</td>\n",
       "      <td>-0.818221</td>\n",
       "      <td>-0.951934</td>\n",
       "      <td>-0.683493</td>\n",
       "      <td>-0.888348</td>\n",
       "      <td>-1.005166</td>\n",
       "      <td>0.671871</td>\n",
       "      <td>0.132434</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.647087</td>\n",
       "      <td>1.035458</td>\n",
       "      <td>-0.669891</td>\n",
       "      <td>-0.636120</td>\n",
       "      <td>-0.476402</td>\n",
       "      <td>-0.531335</td>\n",
       "      <td>-0.990740</td>\n",
       "      <td>-1.196269</td>\n",
       "      <td>0.363061</td>\n",
       "      <td>-0.372215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570612</td>\n",
       "      <td>-1.021855</td>\n",
       "      <td>0.510866</td>\n",
       "      <td>0.408905</td>\n",
       "      <td>-0.045084</td>\n",
       "      <td>-0.310914</td>\n",
       "      <td>-0.386171</td>\n",
       "      <td>-0.065263</td>\n",
       "      <td>-0.232778</td>\n",
       "      <td>-0.535625</td>\n",
       "      <td>...</td>\n",
       "      <td>0.319276</td>\n",
       "      <td>-0.972569</td>\n",
       "      <td>0.280965</td>\n",
       "      <td>0.134281</td>\n",
       "      <td>-0.467608</td>\n",
       "      <td>-0.472006</td>\n",
       "      <td>-0.138962</td>\n",
       "      <td>0.016578</td>\n",
       "      <td>-0.127664</td>\n",
       "      <td>-0.710370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>-0.860588</td>\n",
       "      <td>-0.549435</td>\n",
       "      <td>-0.846758</td>\n",
       "      <td>-0.785752</td>\n",
       "      <td>0.842278</td>\n",
       "      <td>-0.447664</td>\n",
       "      <td>-0.697999</td>\n",
       "      <td>-0.583830</td>\n",
       "      <td>-0.311607</td>\n",
       "      <td>0.150131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.775109</td>\n",
       "      <td>0.187925</td>\n",
       "      <td>-0.787857</td>\n",
       "      <td>-0.695690</td>\n",
       "      <td>0.249076</td>\n",
       "      <td>-0.631995</td>\n",
       "      <td>-0.765225</td>\n",
       "      <td>-0.566574</td>\n",
       "      <td>0.256534</td>\n",
       "      <td>-0.231776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>-0.086056</td>\n",
       "      <td>-0.798834</td>\n",
       "      <td>-0.053251</td>\n",
       "      <td>-0.195421</td>\n",
       "      <td>0.355099</td>\n",
       "      <td>0.532539</td>\n",
       "      <td>-0.095310</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>-0.506801</td>\n",
       "      <td>0.483424</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083880</td>\n",
       "      <td>-0.756033</td>\n",
       "      <td>0.114565</td>\n",
       "      <td>-0.101734</td>\n",
       "      <td>0.433744</td>\n",
       "      <td>0.741246</td>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.400409</td>\n",
       "      <td>-0.457724</td>\n",
       "      <td>1.100466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>-0.647311</td>\n",
       "      <td>-0.446318</td>\n",
       "      <td>-0.670242</td>\n",
       "      <td>-0.621444</td>\n",
       "      <td>-0.329040</td>\n",
       "      <td>-0.756086</td>\n",
       "      <td>-0.722523</td>\n",
       "      <td>-0.797030</td>\n",
       "      <td>0.187639</td>\n",
       "      <td>-0.323262</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.560362</td>\n",
       "      <td>-0.141953</td>\n",
       "      <td>-0.607491</td>\n",
       "      <td>-0.537882</td>\n",
       "      <td>-0.300528</td>\n",
       "      <td>-0.469339</td>\n",
       "      <td>-0.572761</td>\n",
       "      <td>-0.880137</td>\n",
       "      <td>-0.125917</td>\n",
       "      <td>-0.099598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2.144933</td>\n",
       "      <td>0.448162</td>\n",
       "      <td>2.259753</td>\n",
       "      <td>2.343085</td>\n",
       "      <td>-0.110505</td>\n",
       "      <td>1.868645</td>\n",
       "      <td>1.704113</td>\n",
       "      <td>1.543105</td>\n",
       "      <td>-0.285331</td>\n",
       "      <td>-0.065182</td>\n",
       "      <td>...</td>\n",
       "      <td>2.483269</td>\n",
       "      <td>0.482278</td>\n",
       "      <td>2.658104</td>\n",
       "      <td>2.635688</td>\n",
       "      <td>-0.177417</td>\n",
       "      <td>1.529859</td>\n",
       "      <td>1.622939</td>\n",
       "      <td>1.092515</td>\n",
       "      <td>-0.031614</td>\n",
       "      <td>0.306298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>-0.577154</td>\n",
       "      <td>0.863028</td>\n",
       "      <td>-0.528298</td>\n",
       "      <td>-0.576939</td>\n",
       "      <td>-1.826769</td>\n",
       "      <td>0.126410</td>\n",
       "      <td>-0.075742</td>\n",
       "      <td>-0.457733</td>\n",
       "      <td>-2.229763</td>\n",
       "      <td>0.620575</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.742071</td>\n",
       "      <td>0.571937</td>\n",
       "      <td>-0.567080</td>\n",
       "      <td>-0.666079</td>\n",
       "      <td>-1.901416</td>\n",
       "      <td>0.522594</td>\n",
       "      <td>0.164345</td>\n",
       "      <td>-0.039335</td>\n",
       "      <td>-1.152771</td>\n",
       "      <td>0.576712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>171 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0      -0.767981     -0.055433       -0.795918  -0.721932        -0.589333   \n",
       "1      -0.116925     -0.731688       -0.158591  -0.209416        -0.875377   \n",
       "2       1.100998     -0.544639        1.047734   0.940735        -0.426476   \n",
       "3      -0.922326      1.220340       -0.929322  -0.818221        -0.951934   \n",
       "4       0.570612     -1.021855        0.510866   0.408905        -0.045084   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "166    -0.860588     -0.549435       -0.846758  -0.785752         0.842278   \n",
       "167    -0.086056     -0.798834       -0.053251  -0.195421         0.355099   \n",
       "168    -0.647311     -0.446318       -0.670242  -0.621444        -0.329040   \n",
       "169     2.144933      0.448162        2.259753   2.343085        -0.110505   \n",
       "170    -0.577154      0.863028       -0.528298  -0.576939        -1.826769   \n",
       "\n",
       "     compactness_mean  concavity_mean  points_mean  symmetry_mean  \\\n",
       "0           -0.996232       -0.780212    -0.661564       0.810759   \n",
       "1           -0.728226       -0.760262    -0.697520       0.281483   \n",
       "2            0.438365        0.300001     0.371772      -0.289084   \n",
       "3           -0.683493       -0.888348    -1.005166       0.671871   \n",
       "4           -0.310914       -0.386171    -0.065263      -0.232778   \n",
       "..                ...             ...          ...            ...   \n",
       "166         -0.447664       -0.697999    -0.583830      -0.311607   \n",
       "167          0.532539       -0.095310     0.071722      -0.506801   \n",
       "168         -0.756086       -0.722523    -0.797030       0.187639   \n",
       "169          1.868645        1.704113     1.543105      -0.285331   \n",
       "170          0.126410       -0.075742    -0.457733      -2.229763   \n",
       "\n",
       "     dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0         -0.417646  ...     -0.785433       0.137175        -0.806874   \n",
       "1         -0.839423  ...     -0.273344      -0.865993        -0.216452   \n",
       "2         -0.675726  ...      0.870599      -0.559798         0.797992   \n",
       "3          0.132434  ...     -0.647087       1.035458        -0.669891   \n",
       "4         -0.535625  ...      0.319276      -0.972569         0.280965   \n",
       "..              ...  ...           ...            ...              ...   \n",
       "166        0.150131  ...     -0.775109       0.187925        -0.787857   \n",
       "167        0.483424  ...      0.083880      -0.756033         0.114565   \n",
       "168       -0.323262  ...     -0.560362      -0.141953        -0.607491   \n",
       "169       -0.065182  ...      2.483269       0.482278         2.658104   \n",
       "170        0.620575  ...     -0.742071       0.571937        -0.567080   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0     -0.716765         -0.854530          -0.972772        -0.923478   \n",
       "1     -0.348722         -0.911689          -0.222689        -0.624656   \n",
       "2      0.733636         -0.216988           0.157285         0.858626   \n",
       "3     -0.636120         -0.476402          -0.531335        -0.990740   \n",
       "4      0.134281         -0.467608          -0.472006        -0.138962   \n",
       "..          ...               ...                ...              ...   \n",
       "166   -0.695690          0.249076          -0.631995        -0.765225   \n",
       "167   -0.101734          0.433744           0.741246         0.097336   \n",
       "168   -0.537882         -0.300528          -0.469339        -0.572761   \n",
       "169    2.635688         -0.177417           1.529859         1.622939   \n",
       "170   -0.666079         -1.901416           0.522594         0.164345   \n",
       "\n",
       "     points_worst  symmetry_worst  dimension_worst  \n",
       "0       -0.752143        0.726302        -0.720284  \n",
       "1       -0.633669        0.824098        -0.330910  \n",
       "2        0.630104       -0.015897        -0.042321  \n",
       "3       -1.196269        0.363061        -0.372215  \n",
       "4        0.016578       -0.127664        -0.710370  \n",
       "..            ...             ...              ...  \n",
       "166     -0.566574        0.256534        -0.231776  \n",
       "167      0.400409       -0.457724         1.100466  \n",
       "168     -0.880137       -0.125917        -0.099598  \n",
       "169      1.092515       -0.031614         0.306298  \n",
       "170     -0.039335       -1.152771         0.576712  \n",
       "\n",
       "[171 rows x 30 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scaling for training data\n",
    "scaled_X_train = pd.DataFrame(scaler.fit_transform(X_train), columns = X_train.columns)\n",
    "scaled_X_train\n",
    "\n",
    "#Scaling for testing data\n",
    "scaled_X_test = pd.DataFrame(scaler.transform(X_test), columns = X_test.columns)\n",
    "scaled_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the data based on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Building :\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3, metric = 'euclidean')\n",
    "\n",
    "#Apply the knn object on the dataset(Traing Phase)\n",
    "knn.fit(scaled_X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction on the data\n",
    "#predict function--> gives the predicted values\n",
    "#Syntax: objectName.predict(Input)\n",
    "y_train_pred = knn.predict(scaled_X_train)\n",
    "y_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.98      1.00      0.99       257\n",
      "           M       1.00      0.96      0.98       141\n",
      "\n",
      "    accuracy                           0.99       398\n",
      "   macro avg       0.99      0.98      0.99       398\n",
      "weighted avg       0.99      0.99      0.99       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check the Accuracy, classifivation report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train,y_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9181286549707602,\n",
       " 0.9473684210526315,\n",
       " 0.9590643274853801,\n",
       " 0.9415204678362573,\n",
       " 0.9590643274853801,\n",
       " 0.9590643274853801,\n",
       " 0.9649122807017544,\n",
       " 0.9532163742690059,\n",
       " 0.9590643274853801,\n",
       " 0.9532163742690059,\n",
       " 0.9532163742690059,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315,\n",
       " 0.935672514619883,\n",
       " 0.9473684210526315,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9415204678362573,\n",
       " 0.9473684210526315]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for optimum k-value\n",
    "#Build the model with multiple k valuess--> error\n",
    "from sklearn.metrics import accuracy_score\n",
    "scores = []\n",
    "for k in range(1, 20):\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = k)\n",
    "    knn_model.fit(scaled_X_train, y_train)\n",
    "    pred_test = knn_model.predict(scaled_X_test)\n",
    "    scores.append(accuracy_score(y_test,pred_test))\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0xeffad88>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot of K values and Scores\n",
    "plt.plot(range(1,20), scores, marker='o', markerfacecolor = 'r', linestyle='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=7, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Optimum k value as 7\n",
    "final_model = KNeighborsClassifier(n_neighbors = 7, metric = 'euclidean')\n",
    "final_model.fit(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M',\n",
       "       'M', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'M', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'M', 'M', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B', 'M', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'M', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B',\n",
       "       'B', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'M',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B', 'B', 'B', 'M',\n",
       "       'B', 'B', 'M', 'M', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M', 'M', 'B', 'B',\n",
       "       'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'M', 'B',\n",
       "       'M', 'B', 'B', 'M', 'M', 'B', 'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction on training data\n",
    "final_train_pred = final_model.predict(scaled_X_train)\n",
    "final_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xee0cbc8>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "sns.heatmap(confusion_matrix(y_train, final_train_pred), annot = True, fmt = 'd')\n",
    "#d--> integer formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      1.00      0.99       257\n",
      "           M       1.00      0.95      0.97       141\n",
      "\n",
      "    accuracy                           0.98       398\n",
      "   macro avg       0.99      0.98      0.98       398\n",
      "weighted avg       0.98      0.98      0.98       398\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report:\n",
    "print(classification_report(y_train,final_train_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'M',\n",
       "       'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'M', 'B', 'M', 'M', 'M',\n",
       "       'M', 'B', 'M', 'B', 'B', 'M', 'B', 'B', 'B', 'B', 'M', 'B', 'M',\n",
       "       'B', 'M', 'M', 'M', 'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'M',\n",
       "       'M', 'M', 'B', 'M', 'M', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'M', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'M', 'B', 'M',\n",
       "       'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'M', 'B', 'B',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'B', 'M',\n",
       "       'B', 'M', 'B', 'B', 'B', 'B', 'B', 'M', 'M', 'M', 'B', 'B', 'B',\n",
       "       'M', 'M', 'M', 'B', 'B', 'M', 'B', 'B', 'M', 'B', 'M', 'M', 'B',\n",
       "       'B', 'B', 'B', 'B', 'B', 'B', 'B', 'M', 'B', 'M', 'B', 'B', 'B',\n",
       "       'M', 'B'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Prediction on test data\n",
    "final_test_pred = final_model.predict(scaled_X_test) #y_test\n",
    "final_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0xd937708>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Compare actual values of test data(y_test) and final_test_pred(model predicted values)\n",
    "# Confuison_matrix(actualValues, predictedValues)\n",
    "sns.heatmap(confusion_matrix(y_test, final_test_pred), annot = True, fmt = 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.95      0.99      0.97       100\n",
      "           M       0.99      0.93      0.96        71\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.96      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classifcation Report for test data:\n",
    "print(classification_report(y_test, final_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
